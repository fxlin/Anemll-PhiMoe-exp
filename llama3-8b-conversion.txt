llama3-8b-conversion.txt


(....)


Assistant: I am LLaMA, an AI model developed by Meta AI that can understand and respond to human input in the form of text. I'm a large language model, trained on a massive dataset of text from the internet, which allows me to generate human-like responses to a wide range of topics and questions. I'm not a human, but a computer program designed to simulate conversation and answer questions to the best of my ability based on my training. I don't have personal opinions, emotions, or experiences, but I'm here to help you with any questions or topics you'd
 like to discuss!                                                                            12.3 t/s

Prefill: 139.7ms (100.2 t/s)
Inference: 12.5 t/s
Total: Generated 121 tokens in 9.80s
                                                                                             To chat with the model, use:

Option 1 - Using meta.yaml (recommended):
python /Users/felixlin/workspace-apple-silicon/Anemll/tests/chat.py \
    --meta "/Users/felixlin/models/llama-3-8b-Instruct-coreml-fxl/meta.yaml"

Or for full conversation mode:
python /Users/felixlin/workspace-apple-silicon/Anemll/tests/chat_full.py \
    --meta "/Users/felixlin/models/llama-3-8b-Instruct-coreml-fxl/meta.yaml"

Option 2 - Manual configuration:
python /Users/felixlin/workspace-apple-silicon/Anemll/tests/chat.py \
    --embed llama_embeddings \
    --lmhead llama_lm_head_lut6 \
    --ffn llama_FFN_PF_lut4_chunk_01of02 \
    --tokenizer "/Users/felixlin/models/llama-3-8b-Instruct-coreml-fxl" \
    --context-length 512 \
    --d "/Users/felixlin/models/llama-3-8b-Instruct-coreml-fxl"
Conversion completed successfully!