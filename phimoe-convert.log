
> /Users/felixlin/workspace-apple-silicon/Anemll/anemll/ane_converter/phimoe_converter.py(848)convert_prefill()
-> mlmodel = ct.convert(
(Pdb) traced_model.graph.nodes()
<iterator object at 0x10d8cb6f0>
(Pdb) for node in traced_model.graph.nodes():
*** IndentationError: expected an indented block
(Pdb) for node in traced_model.graph.nodes():
*** IndentationError: expected an indented block
(Pdb) 
*** IndentationError: expected an indented block
(Pdb) 
*** IndentationError: expected an indented block
(Pdb) --KeyboardInterrupt--
(Pdb) ^D
Error during prefill conversion: 

Error during conversion: 
Traceback (most recent call last):
  File "/Users/felixlin/workspace-apple-silicon/Anemll/anemll/ane_converter/phimoe_converter.py", line 1106, in main
  File "/Users/felixlin/workspace-apple-silicon/Anemll/anemll/ane_converter/phimoe_converter.py", line 964, in test_conversion
    base_name = f'{prefix}_FFN' if split_part == '2' else f'{prefix}_prefill'
  File "/Users/felixlin/workspace-apple-silicon/Anemll/anemll/ane_converter/phimoe_converter.py", line 848, in convert_prefill
    for block in node.blocks():
  File "/Users/felixlin/workspace-apple-silicon/Anemll/anemll/ane_converter/phimoe_converter.py", line 848, in convert_prefill
    for block in node.blocks():
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Error in step 4: Converting Prefill
(myenv-python39) felixlin@felixmacstudio01:~/workspace-apple-silicon/Anemll$ ./anemll/utils/convert_model_phi.sh --model ~/models/Phi-3.5-MoE-instruct/ --output ~/models/Phi-3.5-MoE-instruct-coreml-fxl/ --only 4 
Checking dependencies...
Checking if macOS version is 15 or higher...
Checking if Python is installed...
Checking if pip is installed...
Checking if coremltools is installed via pip...
Checking if coremlcompiler is available...
Displaying coremlcompiler version...
coremlcompiler version: 3404.23.1
Checking if Python3 is installed...
Checking for model files in the provided directory: /Users/felixlin/models/Phi-3.5-MoE-instruct
Checking for supported architectures in config.json...
All dependencies are satisfied.
Checking dependencies...
Checking if macOS version is 15 or higher...
Checking if Python is installed...
Checking if pip is installed...
Checking if coremltools is installed via pip...
Checking if coremlcompiler is available...
Displaying coremlcompiler version...
coremlcompiler version: 3404.23.1
Checking if Python3 is installed...
Checking for model files in the provided directory: /Users/felixlin/models/Phi-3.5-MoE-instruct
Checking for supported architectures in config.json...
All dependencies are satisfied.
Skipping step 1: Converting Embeddings
Skipping step 2: Converting LM Head
Skipping step 3: Converting FFN
Step 4: Converting Prefill

Converting model from: /Users/felixlin/models/Phi-3.5-MoE-instruct
Output filename prefix: phimoe
Batch size: 64
Context length: 512
LUT quantization: 4 bits
Splitting into 2 chunks
Converting part(s): 2_prefill
Loading config from /Users/felixlin/models/Phi-3.5-MoE-instruct/config.json
Unrecognized keys in `rope_scaling` for 'rope_type'='longrope': {'short_mscale', 'long_mscale'}
This model has set a `original_max_position_embeddings` field, to be used together with `max_position_embeddings` to determine a scaling factor. Please set the `factor` field of `rope_scaling`with this ratio instead -- we recommend the use of this field over `original_max_position_embeddings`, as it is compatible with most model architectures.

Loaded model config:
  hidden_size: 4096
  vocab_size: 32064

[TRACE] RotaryEmbedding initialized:
  dim: 128
  max_position_embeddings: 131072
  base: 10000.0
  inv_freq shape: torch.Size([64])
  cos_cached shape: torch.Size([1, 131072, 128])
  sin_cached shape: torch.Size([1, 131072, 128])
  cos_cached[0,0,:5]: [1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836]
  sin_cached[0,0,:5]: [0.0, 0.0, 0.0, 0.0, 0.0]

[TRACE] RotaryEmbedding initialized:
  dim: 128
  max_position_embeddings: 131072
  base: 10000.0
  inv_freq shape: torch.Size([64])
  cos_cached shape: torch.Size([1, 131072, 128])
  sin_cached shape: torch.Size([1, 131072, 128])
  cos_cached[0,0,:5]: [1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836]
  sin_cached[0,0,:5]: [0.0, 0.0, 0.0, 0.0, 0.0]
Initialized unified KV kv_cache_0 with shape: torch.Size([4, 8, 512, 128])
Created lm_head8_1 through lm_head8_8

Loading pretrained weights...
Loading pretrained weights...
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 320.04it/s]
Split lm_head weight into lm_head8_1.weight with shape torch.Size([4008, 4096, 1, 1])
Split lm_head weight into lm_head8_2.weight with shape torch.Size([4008, 4096, 1, 1])
Split lm_head weight into lm_head8_3.weight with shape torch.Size([4008, 4096, 1, 1])
Split lm_head weight into lm_head8_4.weight with shape torch.Size([4008, 4096, 1, 1])
Split lm_head weight into lm_head8_5.weight with shape torch.Size([4008, 4096, 1, 1])
Split lm_head weight into lm_head8_6.weight with shape torch.Size([4008, 4096, 1, 1])
Split lm_head weight into lm_head8_7.weight with shape torch.Size([4008, 4096, 1, 1])
Split lm_head weight into lm_head8_8.weight with shape torch.Size([4008, 4096, 1, 1])
Loading model.embed_tokens.weight with shape torch.Size([32064, 4096])
Moving model.embed_tokens.weight to embed_tokens.weight
(after loading emb/head) Missing keys: ['model.kv_cache_0', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.0.block_sparse_moe.gate.weight', 'model.layers.0.block_sparse_moe.experts.0.w1.weight', 'model.layers.0.block_sparse_moe.experts.0.w2.weight', 'model.layers.0.block_sparse_moe.experts.0.w3.weight', 'model.layers.0.block_sparse_moe.experts.1.w1.weight', 'model.layers.0.block_sparse_moe.experts.1.w2.weight', 'model.layers.0.block_sparse_moe.experts.1.w3.weight', 'model.layers.0.block_sparse_moe.experts.2.w1.weight', 'model.layers.0.block_sparse_moe.experts.2.w2.weight', 'model.layers.0.block_sparse_moe.experts.2.w3.weight', 'model.layers.0.block_sparse_moe.experts.3.w1.weight', 'model.layers.0.block_sparse_moe.experts.3.w2.weight', 'model.layers.0.block_sparse_moe.experts.3.w3.weight', 'model.layers.0.block_sparse_moe.experts.4.w1.weight', 'model.layers.0.block_sparse_moe.experts.4.w2.weight', 'model.layers.0.block_sparse_moe.experts.4.w3.weight', 'model.layers.0.block_sparse_moe.experts.5.w1.weight', 'model.layers.0.block_sparse_moe.experts.5.w2.weight', 'model.layers.0.block_sparse_moe.experts.5.w3.weight', 'model.layers.0.block_sparse_moe.experts.6.w1.weight', 'model.layers.0.block_sparse_moe.experts.6.w2.weight', 'model.layers.0.block_sparse_moe.experts.6.w3.weight', 'model.layers.0.block_sparse_moe.experts.7.w1.weight', 'model.layers.0.block_sparse_moe.experts.7.w2.weight', 'model.layers.0.block_sparse_moe.experts.7.w3.weight', 'model.layers.0.block_sparse_moe.experts.8.w1.weight', 'model.layers.0.block_sparse_moe.experts.8.w2.weight', 'model.layers.0.block_sparse_moe.experts.8.w3.weight', 'model.layers.0.block_sparse_moe.experts.9.w1.weight', 'model.layers.0.block_sparse_moe.experts.9.w2.weight', 'model.layers.0.block_sparse_moe.experts.9.w3.weight', 'model.layers.0.block_sparse_moe.experts.10.w1.weight', 'model.layers.0.block_sparse_moe.experts.10.w2.weight', 'model.layers.0.block_sparse_moe.experts.10.w3.weight', 'model.layers.0.block_sparse_moe.experts.11.w1.weight', 'model.layers.0.block_sparse_moe.experts.11.w2.weight', 'model.layers.0.block_sparse_moe.experts.11.w3.weight', 'model.layers.0.block_sparse_moe.experts.12.w1.weight', 'model.layers.0.block_sparse_moe.experts.12.w2.weight', 'model.layers.0.block_sparse_moe.experts.12.w3.weight', 'model.layers.0.block_sparse_moe.experts.13.w1.weight', 'model.layers.0.block_sparse_moe.experts.13.w2.weight', 'model.layers.0.block_sparse_moe.experts.13.w3.weight', 'model.layers.0.block_sparse_moe.experts.14.w1.weight', 'model.layers.0.block_sparse_moe.experts.14.w2.weight', 'model.layers.0.block_sparse_moe.experts.14.w3.weight', 'model.layers.0.block_sparse_moe.experts.15.w1.weight', 'model.layers.0.block_sparse_moe.experts.15.w2.weight', 'model.layers.0.block_sparse_moe.experts.15.w3.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.input_layernorm.bias', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.0.post_attention_layernorm.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.1.block_sparse_moe.gate.weight', 'model.layers.1.block_sparse_moe.experts.0.w1.weight', 'model.layers.1.block_sparse_moe.experts.0.w2.weight', 'model.layers.1.block_sparse_moe.experts.0.w3.weight', 'model.layers.1.block_sparse_moe.experts.1.w1.weight', 'model.layers.1.block_sparse_moe.experts.1.w2.weight', 'model.layers.1.block_sparse_moe.experts.1.w3.weight', 'model.layers.1.block_sparse_moe.experts.2.w1.weight', 'model.layers.1.block_sparse_moe.experts.2.w2.weight', 'model.layers.1.block_sparse_moe.experts.2.w3.weight', 'model.layers.1.block_sparse_moe.experts.3.w1.weight', 'model.layers.1.block_sparse_moe.experts.3.w2.weight', 'model.layers.1.block_sparse_moe.experts.3.w3.weight', 'model.layers.1.block_sparse_moe.experts.4.w1.weight', 'model.layers.1.block_sparse_moe.experts.4.w2.weight', 'model.layers.1.block_sparse_moe.experts.4.w3.weight', 'model.layers.1.block_sparse_moe.experts.5.w1.weight', 'model.layers.1.block_sparse_moe.experts.5.w2.weight', 'model.layers.1.block_sparse_moe.experts.5.w3.weight', 'model.layers.1.block_sparse_moe.experts.6.w1.weight', 'model.layers.1.block_sparse_moe.experts.6.w2.weight', 'model.layers.1.block_sparse_moe.experts.6.w3.weight', 'model.layers.1.block_sparse_moe.experts.7.w1.weight', 'model.layers.1.block_sparse_moe.experts.7.w2.weight', 'model.layers.1.block_sparse_moe.experts.7.w3.weight', 'model.layers.1.block_sparse_moe.experts.8.w1.weight', 'model.layers.1.block_sparse_moe.experts.8.w2.weight', 'model.layers.1.block_sparse_moe.experts.8.w3.weight', 'model.layers.1.block_sparse_moe.experts.9.w1.weight', 'model.layers.1.block_sparse_moe.experts.9.w2.weight', 'model.layers.1.block_sparse_moe.experts.9.w3.weight', 'model.layers.1.block_sparse_moe.experts.10.w1.weight', 'model.layers.1.block_sparse_moe.experts.10.w2.weight', 'model.layers.1.block_sparse_moe.experts.10.w3.weight', 'model.layers.1.block_sparse_moe.experts.11.w1.weight', 'model.layers.1.block_sparse_moe.experts.11.w2.weight', 'model.layers.1.block_sparse_moe.experts.11.w3.weight', 'model.layers.1.block_sparse_moe.experts.12.w1.weight', 'model.layers.1.block_sparse_moe.experts.12.w2.weight', 'model.layers.1.block_sparse_moe.experts.12.w3.weight', 'model.layers.1.block_sparse_moe.experts.13.w1.weight', 'model.layers.1.block_sparse_moe.experts.13.w2.weight', 'model.layers.1.block_sparse_moe.experts.13.w3.weight', 'model.layers.1.block_sparse_moe.experts.14.w1.weight', 'model.layers.1.block_sparse_moe.experts.14.w2.weight', 'model.layers.1.block_sparse_moe.experts.14.w3.weight', 'model.layers.1.block_sparse_moe.experts.15.w1.weight', 'model.layers.1.block_sparse_moe.experts.15.w2.weight', 'model.layers.1.block_sparse_moe.experts.15.w3.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.input_layernorm.bias', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.post_attention_layernorm.bias', 'model.norm.weight', 'model.norm.bias']
Reshaped MoE router weight layers.8.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.9.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.21.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.22.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.31.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.6.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.7.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE weight layers.0.block_sparse_moe.experts.0.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.0.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.0.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.1.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.1.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.1.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.10.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.10.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.10.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.11.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.11.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.11.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.12.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.12.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.12.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.13.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.13.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.13.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.14.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.14.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.14.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.15.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.15.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.15.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.2.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.2.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.2.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.3.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.3.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.3.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.4.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.4.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.4.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.5.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.5.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.5.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.6.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.6.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.6.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.7.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.7.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.7.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.8.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.8.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.8.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.9.w1.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.9.w2.weight from torch.Size([4096, 6400]) to torch.Size([4096, 6400, 1, 1])... (& more layers...
Reshaped MoE weight layers.0.block_sparse_moe.experts.9.w3.weight from torch.Size([6400, 4096]) to torch.Size([6400, 4096, 1, 1])... (& more layers...
Reshaped MoE router weight layers.0.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped layers.0.self_attn.k_proj.weight from torch.Size([1024, 4096]) to torch.Size([1024, 4096, 1, 1])... (& more layers...
Keeping o_proj weights as 2D: layers.0.self_attn.o_proj.weight shape torch.Size([4096, 4096])... (& more layers...
Reshaped layers.0.self_attn.q_proj.weight from torch.Size([4096, 4096]) to torch.Size([4096, 4096, 1, 1])... (& more layers...
Reshaped layers.0.self_attn.v_proj.weight from torch.Size([1024, 4096]) to torch.Size([1024, 4096, 1, 1])... (& more layers...
Reshaped MoE router weight layers.1.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.23.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.24.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.29.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.30.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.27.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.28.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.18.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.19.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.2.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.3.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.12.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.13.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.14.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.15.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.25.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.26.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.20.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.16.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.17.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.4.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.5.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.10.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Reshaped MoE router weight layers.11.block_sparse_moe.gate.weight from torch.Size([16, 4096]) to torch.Size([16, 4096, 1, 1])
Pretrained weights loaded successfully
Note: The following expected buffers were initialized:
  - kv_cache_0
  - layers.0.self_attn.rotary_emb.inv_freq
  - layers.1.self_attn.rotary_emb.inv_freq

Converting chunk 1/2

Converting transformer prefill mode...
Processing chunk 1/2 (layers 0 to 0)
GetTransformerStates part=2_prefill ENABLE_UNIFIED_CACHE=True num_layers_this_part=4 model.config.num_hidden_layers=2
Tracing prefill model...
PhimoeModel.forward - hidden_states shape: torch.Size([1, 64, 4096])
cos shape: torch.Size([1, 64, 1, 128])
sin shape: torch.Size([1, 64, 1, 128])
[TRACE] get_rotary_embedding_prefill Batched rotary from pos 0:
/Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1223: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  print(f"  cos shape: {cos.shape}, values[0,:5]: {cos[0,0,0,:5].tolist()}")
  cos shape: torch.Size([1, 64, 1, 128]), values[0,:5]: [1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836]
/Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1224: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  print(f"  sin shape: {sin.shape}, values[0,:5]: {sin[0,0,0,:5].tolist()}")
  sin shape: torch.Size([1, 64, 1, 128]), values[0,:5]: [0.0, 0.0, 0.0, 0.0, 0.0]
position_ids=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
position_ids.shape=torch.Size([64])
rotary_emb.shape=torch.Size([1, 64, 1, 128])
[process_layer_prefill] causal_mask.shape= torch.Size([1, 1, 64, 512])

PREFILL - Input shapes:
  hidden_states: torch.Size([1, 64, 4096]), current_pos: tensor([0]), batch: 64
[forward_prefill.0] K_layer_cache.shape= torch.Size([8, 512, 128])
[forward_prefill.1] hidden_states.shape= torch.Size([1, 64, 4096])
[forward_prefill.1] query_states.shape= torch.Size([1, 32, 64, 128])
[forward_prefill.1] key_states.shape= torch.Size([1, 32, 512, 128])
[forward_prefill.1] value_states.shape= torch.Size([1, 32, 512, 128])
[forward_prefill.2] causal_mask.shape= torch.Size([1, 1, 64, 512])
[forward_prefill.2] attn_weights.shape= torch.Size([1, 32, 64, 512])
/Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1439: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  print(f"phimoeModel.forward - hidden_states last 10: {hidden_states[-1, -1, -10:].tolist()}")
phimoeModel.forward - hidden_states last 10: [-0.0007762908935546875, 0.0003619194030761719, 0.00020003318786621094, -0.0009050369262695312, 0.0020427703857421875, 0.0011510848999023438, -0.002025604248046875, -0.026641845703125, -0.0014410018920898438, 0.00018024444580078125]
PhimoeModel.forward - hidden_states shape: torch.Size([1, 64, 4096])
cos shape: torch.Size([1, 64, 1, 128])
sin shape: torch.Size([1, 64, 1, 128])
[TRACE] get_rotary_embedding_prefill Batched rotary from pos 0:
  cos shape: torch.Size([1, 64, 1, 128]), values[0,:5]: [1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836]
  sin shape: torch.Size([1, 64, 1, 128]), values[0,:5]: [0.0, 0.0, 0.0, 0.0, 0.0]
position_ids=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
position_ids.shape=torch.Size([64])
rotary_emb.shape=torch.Size([1, 64, 1, 128])
[process_layer_prefill] causal_mask.shape= torch.Size([1, 1, 64, 512])

PREFILL - Input shapes:
  hidden_states: torch.Size([1, 64, 4096]), current_pos: tensor([0]), batch: 64
[forward_prefill.0] K_layer_cache.shape= torch.Size([8, 512, 128])
[forward_prefill.1] hidden_states.shape= torch.Size([1, 64, 4096])
[forward_prefill.1] query_states.shape= torch.Size([1, 32, 64, 128])
[forward_prefill.1] key_states.shape= torch.Size([1, 32, 512, 128])
[forward_prefill.1] value_states.shape= torch.Size([1, 32, 512, 128])
[forward_prefill.2] causal_mask.shape= torch.Size([1, 1, 64, 512])
[forward_prefill.2] attn_weights.shape= torch.Size([1, 32, 64, 512])
phimoeModel.forward - hidden_states last 10: [-0.0007762908935546875, 0.0003619194030761719, 0.00020003318786621094, -0.0009050369262695312, 0.0020427703857421875, 0.0011510848999023438, -0.002025604248046875, -0.026641845703125, -0.0014410018920898438, 0.00018024444580078125]
PhimoeModel.forward - hidden_states shape: torch.Size([1, 64, 4096])
cos shape: torch.Size([1, 64, 1, 128])
sin shape: torch.Size([1, 64, 1, 128])
[TRACE] get_rotary_embedding_prefill Batched rotary from pos 0:
  cos shape: torch.Size([1, 64, 1, 128]), values[0,:5]: [1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836, 1.2431631088256836]
  sin shape: torch.Size([1, 64, 1, 128]), values[0,:5]: [0.0, 0.0, 0.0, 0.0, 0.0]
position_ids=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
position_ids.shape=torch.Size([64])
rotary_emb.shape=torch.Size([1, 64, 1, 128])
[process_layer_prefill] causal_mask.shape= torch.Size([1, 1, 64, 512])

PREFILL - Input shapes:
  hidden_states: torch.Size([1, 64, 4096]), current_pos: tensor([0]), batch: 64
[forward_prefill.0] K_layer_cache.shape= torch.Size([8, 512, 128])
[forward_prefill.1] hidden_states.shape= torch.Size([1, 64, 4096])
[forward_prefill.1] query_states.shape= torch.Size([1, 32, 64, 128])
[forward_prefill.1] key_states.shape= torch.Size([1, 32, 512, 128])
[forward_prefill.1] value_states.shape= torch.Size([1, 32, 512, 128])
[forward_prefill.2] causal_mask.shape= torch.Size([1, 1, 64, 512])
[forward_prefill.2] attn_weights.shape= torch.Size([1, 32, 64, 512])
phimoeModel.forward - hidden_states last 10: [-0.0007762908935546875, 0.0003619194030761719, 0.00020003318786621094, -0.0009050369262695312, 0.0020427703857421875, 0.0011510848999023438, -0.002025604248046875, -0.026641845703125, -0.0014410018920898438, 0.00018024444580078125]
Node: prim::GetAttr
  Inputs: ['self.1']
  Outputs: ['model.1']
Node: prim::GetAttr
  Inputs: ['model.1']
  Outputs: ['model']
Node: prim::CallMethod
  Inputs: ['model', 'hidden_states.1', 'position_ids.1', 'causal_mask', 'current_pos.1']
  Outputs: ['3586']
> /Users/felixlin/workspace-apple-silicon/Anemll/anemll/ane_converter/phimoe_converter.py(864)convert_prefill()
-> mlmodel = ct.convert(
(Pdb) print(traced_model.graph)
graph(%self.1 : __torch__.PrefillWrapper,
      %hidden_states.1 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=0, device=cpu),
      %position_ids.1 : Long(64, strides=[1], requires_grad=0, device=cpu),
      %causal_mask : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu),
      %current_pos.1 : Long(1, strides=[1], requires_grad=0, device=cpu)):
  %model.1 : __torch__.anemll.models.phimoe_model.PhimoeForCausalLM = prim::GetAttr[name="model"](%self.1)
  %model : __torch__.anemll.models.phimoe_model.PhimoeModel = prim::GetAttr[name="model"](%model.1)
  %3586 : Tensor = prim::CallMethod[name="forward"](%model, %hidden_states.1, %position_ids.1, %causal_mask, %current_pos.1)
  return (%3586)



  %189 : int = aten::Int(%188), scope: __module.model.model
  %190 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%kv_cache_0, %44, %32, %30, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %191 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%190, %41, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %192 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%191, %32, %91, %189, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %193 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%192, %30, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %194 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::copy_(%193, %value_states.5, %36), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %195 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%kv_cache_0, %44, %44, %41, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1282:0
  %K_layer_cache.1 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::squeeze(%195, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1282:0
  %197 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%kv_cache_0, %44, %32, %30, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1283:0
  %V_layer_cache : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::squeeze(%197, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1283:0
  %199 : int = aten::size(%hidden_states.3, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:998:0
  %200 : int = aten::size(%hidden_states.3, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:998:0
  %201 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%K_layer_cache.1, %41, %44, %26, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1004:0
  %K_layer_cache : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%201, %32, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1004:0
  %203 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%V_layer_cache, %41, %44, %26, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1005:0
  %x.13 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%203, %32, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1005:0
  %x.9 : Half(8, 1, 512, 128, strides=[65536, 65536, 128, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%K_layer_cache, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1065:0
  %206 : int[] = prim::ListConstruct(%41, %25, %41, %41), scope: __module.model.model
  %x.11 : Half(8, 4, 512, 128, strides=[262144, 65536, 128, 1], requires_grad=1, device=cpu) = aten::repeat(%x.9, %206), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1066:0
  %208 : int = aten::size(%x.11, %24), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %209 : int = aten::size(%x.11, %27), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %210 : int[] = prim::ListConstruct(%41, %27, %208, %209), scope: __module.model.model
  %key_states : Half(1, 32, 512, 128, strides=[2097152, 65536, 128, 1], requires_grad=1, device=cpu) = aten::view(%x.11, %210), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %x.15 : Half(8, 1, 512, 128, strides=[65536, 65536, 128, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%x.13, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1065:0
  %213 : int[] = prim::ListConstruct(%41, %25, %41, %41), scope: __module.model.model
  %x.17 : Half(8, 4, 512, 128, strides=[262144, 65536, 128, 1], requires_grad=1, device=cpu) = aten::repeat(%x.15, %213), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1066:0
  %215 : int = aten::size(%x.17, %24), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %216 : int = aten::size(%x.17, %27), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %217 : int[] = prim::ListConstruct(%41, %27, %215, %216), scope: __module.model.model
  %value_states : Half(1, 32, 512, 128, strides=[2097152, 65536, 128, 1], requires_grad=1, device=cpu) = aten::view(%x.17, %217), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %219 : Tensor[] = prim::ListConstruct(%query_states, %key_states), scope: __module.model.model
  %220 : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::einsum(%23, %219, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/functional.py:402:0
  %attn_weights : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::div(%220, %22), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1031:0
  %222 : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu) = aten::slice(%causal_mask, %44, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %223 : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu) = aten::slice(%222, %41, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %224 : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu) = aten::slice(%223, %32, %44, %26, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %x.19 : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::add(%attn_weights, %224, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %x_max : Half(1, 32, 64, 1, strides=[2048, 64, 1, 1], requires_grad=1, device=cpu), %227 : Long(1, 32, 64, 1, strides=[2048, 64, 1, 1], requires_grad=0, device=cpu) = aten::max(%x.19, %27, %35), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:893:0
  %x : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::sub(%x.19, %x_max, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:894:0
  %exp_x : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::exp(%x), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:895:0
  %230 : int[] = prim::ListConstruct(%27), scope: __module.model.model
  %231 : Half(1, 32, 64, 1, strides=[2048, 64, 1, 1], requires_grad=1, device=cpu) = aten::sum(%exp_x, %230, %35, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:896:0
  %232 : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::div(%exp_x, %231), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:896:0
  %233 : Tensor[] = prim::ListConstruct(%232, %value_states), scope: __module.model.model
  %attn_output.1 : Half(1, 32, 64, 128, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::einsum(%21, %233, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/functional.py:402:0
  %235 : Half(1, 64, 32, 128, strides=[262144, 128, 8192, 1], requires_grad=1, device=cpu) = aten::transpose(%attn_output.1, %41, %32), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1051:0
  %attn_output.3 : Half(1, 64, 32, 128, strides=[262144, 4096, 128, 1], requires_grad=1, device=cpu) = aten::contiguous(%235, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1051:0
  %237 : int[] = prim::ListConstruct(%199, %200, %33), scope: __module.model.model
  %input.3 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::reshape(%attn_output.3, %237), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1052:0
  %bias.19 : Tensor = prim::GetAttr[name="bias"](%o_proj)
  %weight.117 : Tensor = prim::GetAttr[name="weight"](%o_proj)
  %attn_output : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::linear(%input.3, %weight.117, %bias.19), scope: __module.model.model/__module.model.model.layers.0.self_attn.o_proj # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/linear.py:125:0
  %input.5 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::add(%hidden_states.1, %attn_output, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1293:0
  %bias : Tensor = prim::GetAttr[name="bias"](%post_attention_layernorm)
  %weight.119 : Tensor = prim::GetAttr[name="weight"](%post_attention_layernorm)
  %245 : int[] = prim::ListConstruct(%33), scope: __module.model.model/__module.model.model.layers.0.post_attention_layernorm
  %hidden_states.5 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::layer_norm(%input.5, %245, %weight.119, %bias, %34, %35), scope: __module.model.model/__module.model.model.layers.0.post_attention_layernorm # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2900:0
  %experts : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_15 : __torch__.anemll.models.phimoe_model.___torch_mangle_65.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="15"](%experts)
  %experts.29 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_14 : __torch__.anemll.models.phimoe_model.___torch_mangle_61.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="14"](%experts.29)
  %experts.27 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_13 : __torch__.anemll.models.phimoe_model.___torch_mangle_57.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="13"](%experts.27)
  %experts.25 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_12 : __torch__.anemll.models.phimoe_model.___torch_mangle_53.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="12"](%experts.25)
  %experts.23 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_11 : __torch__.anemll.models.phimoe_model.___torch_mangle_49.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="11"](%experts.23)
  %experts.21 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_10 : __torch__.anemll.models.phimoe_model.___torch_mangle_45.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="10"](%experts.21)
  %experts.19 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_9 : __torch__.anemll.models.phimoe_model.___torch_mangle_41.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="9"](%experts.19)
  %experts.17 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_8 : __torch__.anemll.models.phimoe_model.___torch_mangle_37.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="8"](%experts.17)
  %experts.15 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_7 : __torch__.anemll.models.phimoe_model.___torch_mangle_33.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="7"](%experts.15)
  %experts.13 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_6 : __torch__.anemll.models.phimoe_model.___torch_mangle_29.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="6"](%experts.13)
  %experts.11 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_5 : __torch__.anemll.models.phimoe_model.___torch_mangle_25.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="5"](%experts.11)
  %experts.9 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_4 : __torch__.anemll.models.phimoe_model.___torch_mangle_21.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="4"](%experts.9)
  %experts.7 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_3 : __torch__.anemll.models.phimoe_model.___torch_mangle_17.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="3"](%experts.7)
  %experts.5 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_2 : __torch__.anemll.models.phimoe_model.___torch_mangle_13.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="2"](%experts.5)
  %experts.3 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_1 : __torch__.anemll.models.phimoe_model.___torch_mangle_9.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="1"](%experts.3)
  %experts.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_0.13 : __torch__.anemll.models.phimoe_model.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="0"](%experts.1)
  %gate : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="gate"](%block_sparse_moe)
  %280 : int = aten::size(%hidden_states.5, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:593:0
  %batch_size : Long(device=cpu) = prim::NumToTensor(%280), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %282 : int = aten::size(%hidden_states.5, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:593:0
  %sequence_length : Long(device=cpu) = prim::NumToTensor(%282), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %284 : int = aten::size(%hidden_states.5, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:593:0
  %285 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.7 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.5, %285), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:599:0
  %287 : Long(requires_grad=0, device=cpu) = aten::mul(%batch_size, %sequence_length), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:602:0
  %288 : int = aten::Int(%287), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %289 : int[] = prim::ListConstruct(%288, %284, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %input.7 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.7, %289), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:602:0
  %weight.121 : Tensor = prim::GetAttr[name="weight"](%gate)
  %292 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %293 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %294 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %295 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %router_logits : Half(64, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.7, %weight.121, %40, %292, %293, %294, %36, %295, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %297 : Long(requires_grad=0, device=cpu) = aten::mul(%batch_size, %sequence_length), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:604:0
  %298 : int = aten::Int(%297), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %299 : int[] = prim::ListConstruct(%298, %8), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %scores : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::view(%router_logits, %299), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:604:0
  %mask_logits_threshold.1 : Half(64, 1, strides=[1, 1], requires_grad=0, device=cpu), %max_ind.1 : Long(64, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::max(%scores, %27, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:410:0
  %303 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::abs(%scores), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:411:0
  %factor.1 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::clamp(%303, %mask_logits_threshold.1, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:411:0
  %305 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::sub(%mask_logits_threshold.1, %scores, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:412:0
  %306 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::div(%305, %factor.1), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:412:0
  %mask_logits_threshold.3 : Bool(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::gt(%306, %9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:412:0
  %masked_gates.1 : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::masked_fill(%scores, %mask_logits_threshold.3, %10), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:415:0
  %masked_gates : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::softmax(%masked_gates.1, %27, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:430:0
  %multiplier_o : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::gather(%masked_gates, %27, %max_ind.1, %36), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:431:0
  %masked_scores : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::scatter(%scores, %27, %max_ind.1, %10), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:455:0
  %mask_logits_threshold.5 : Half(64, 1, strides=[1, 1], requires_grad=0, device=cpu), %max_ind : Long(64, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::max(%masked_scores, %27, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:463:0
  %314 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::abs(%scores), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:464:0
  %factor : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::clamp(%314, %mask_logits_threshold.5, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:464:0
  %316 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::sub(%mask_logits_threshold.5, %scores, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:465:0
  %317 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::div(%316, %factor), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:465:0
  %mask_logits_threshold : Bool(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::gt(%317, %9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:465:0
  %masked_gates_top2.1 : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::masked_fill(%masked_scores, %mask_logits_threshold, %10), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:468:0
  %masked_gates_top2 : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::softmax(%masked_gates_top2.1, %27, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:484:0
  %multiplier_top2_o : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::gather(%masked_gates_top2, %27, %max_ind, %36), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:485:0
  %322 : Tensor[] = prim::ListConstruct(%multiplier_o, %multiplier_top2_o), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %routing_weights : Half(64, 2, strides=[2, 1], requires_grad=1, device=cpu) = aten::concat(%322, %27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:508:0
  %324 : Tensor[] = prim::ListConstruct(%max_ind.1, %max_ind), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %selected_experts : Long(64, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::concat(%324, %27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:509:0
  %326 : Long(requires_grad=0, device=cpu) = aten::mul(%batch_size, %sequence_length), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:616:0
  %327 : int = aten::Int(%326), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %328 : int[] = prim::ListConstruct(%327, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %final_hidden_states.1 : Half(64, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::zeros(%328, %37, %40, %11, %36), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:615:0
  %330 : Long(64, 2, 16, strides=[32, 16, 1], requires_grad=0, device=cpu) = aten::one_hot(%selected_experts, %8), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:621:0
  %331 : int[] = prim::ListConstruct(%32, %41, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %expert_mask : Long(16, 2, 64, strides=[1, 16, 32], requires_grad=0, device=cpu) = aten::permute(%330, %331), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:621:0
  %333 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %334 : Tensor[] = aten::where(%333), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.1 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.1 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%334), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %337 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %338 : Tensor?[] = prim::ListConstruct(%40, %top_x.1), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %339 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%337, %338), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %340 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.9 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%339, %340), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.1 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="w2"](%_0.13)
  %w3.1 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="w3"](%_0.13)
  %w1.1 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="w1"](%_0.13)
  %345 : int = aten::size(%hidden_states.9, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %346 : int = aten::size(%hidden_states.9, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %347 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0
  %input.9 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.9, %347), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.123 : Tensor = prim::GetAttr[name="weight"](%w1.1)
  %350 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %351 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %352 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %353 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %input.11 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.9, %weight.123, %40, %350, %351, %352, %36, %353, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %355 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.11), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.125 : Tensor = prim::GetAttr[name="weight"](%w3.1)
  %357 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %358 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %359 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %360 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %361 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.9, %weight.125, %40, %357, %358, %359, %36, %360, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.13 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%355, %361), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.127 : Tensor = prim::GetAttr[name="weight"](%w2.1)
  %364 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %365 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %366 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %367 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %out.1 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.13, %weight.127, %40, %364, %365, %366, %36, %367, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %369 : int[] = prim::ListConstruct(%345, %346), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0
  %370 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.1, %369), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %371 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %372 : Tensor?[] = prim::ListConstruct(%top_x.1, %idx.1), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %373 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%371, %372), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.1 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%370, %373), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.3 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.1, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.3 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.1, %44, %top_x.1, %current_hidden_states.3, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %377 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %378 : Tensor[] = aten::where(%377), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.3 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.3 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%378), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %381 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %382 : Tensor?[] = prim::ListConstruct(%40, %top_x.3), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %383 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%381, %382), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %384 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.11 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%383, %384), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.3 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="w2"](%_1)
  %w3.3 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="w3"](%_1)
  %w1.3 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="w1"](%_1)
  %389 : int = aten::size(%hidden_states.11, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %390 : int = aten::size(%hidden_states.11, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %391 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1
  %input.15 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.11, %391), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.129 : Tensor = prim::GetAttr[name="weight"](%w1.3)
  %394 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %395 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %396 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %397 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %input.17 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.15, %weight.129, %40, %394, %395, %396, %36, %397, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %399 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.131 : Tensor = prim::GetAttr[name="weight"](%w3.3)
  %401 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %402 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %403 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %404 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %405 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.15, %weight.131, %40, %401, %402, %403, %36, %404, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.19 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%399, %405), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.133 : Tensor = prim::GetAttr[name="weight"](%w2.3)
  %408 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %409 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %410 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %411 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %out.3 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.19, %weight.133, %40, %408, %409, %410, %36, %411, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %413 : int[] = prim::ListConstruct(%389, %390), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1
  %414 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.3, %413), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %415 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %416 : Tensor?[] = prim::ListConstruct(%top_x.3, %idx.3), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %417 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%415, %416), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.5 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%414, %417), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.7 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.5, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.5 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.3, %44, %top_x.3, %current_hidden_states.7, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %421 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %422 : Tensor[] = aten::where(%421), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.5 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.5 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%422), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %425 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %426 : Tensor?[] = prim::ListConstruct(%40, %top_x.5), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %427 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%425, %426), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %428 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.13 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%427, %428), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.5 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="w2"](%_2)
  %w3.5 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="w3"](%_2)
  %w1.5 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="w1"](%_2)
  %433 : int = aten::size(%hidden_states.13, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %434 : int = aten::size(%hidden_states.13, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %435 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2
  %input.21 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.13, %435), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.135 : Tensor = prim::GetAttr[name="weight"](%w1.5)
  %438 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %439 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %440 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %441 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %input.23 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.21, %weight.135, %40, %438, %439, %440, %36, %441, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %443 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.23), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.137 : Tensor = prim::GetAttr[name="weight"](%w3.5)
  %445 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %446 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %447 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %448 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %449 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.21, %weight.137, %40, %445, %446, %447, %36, %448, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.25 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%443, %449), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.139 : Tensor = prim::GetAttr[name="weight"](%w2.5)
  %452 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %453 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %454 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %455 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %out.5 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.25, %weight.139, %40, %452, %453, %454, %36, %455, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %457 : int[] = prim::ListConstruct(%433, %434), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2
  %458 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.5, %457), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %459 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %460 : Tensor?[] = prim::ListConstruct(%top_x.5, %idx.5), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %461 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%459, %460), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.9 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%458, %461), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.11 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.9, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.7 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.5, %44, %top_x.5, %current_hidden_states.11, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %465 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %30), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %466 : Tensor[] = aten::where(%465), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.7 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.7 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%466), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %469 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %470 : Tensor?[] = prim::ListConstruct(%40, %top_x.7), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %471 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%469, %470), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %472 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.15 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%471, %472), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.7 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="w2"](%_3)
  %w3.7 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="w3"](%_3)
  %w1.7 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="w1"](%_3)
  %477 : int = aten::size(%hidden_states.15, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %478 : int = aten::size(%hidden_states.15, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %479 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3
  %input.27 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.15, %479), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.141 : Tensor = prim::GetAttr[name="weight"](%w1.7)
  %482 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %483 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %484 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %485 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %input.29 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.27, %weight.141, %40, %482, %483, %484, %36, %485, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %487 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.143 : Tensor = prim::GetAttr[name="weight"](%w3.7)
  %489 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %490 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %491 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %492 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %493 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.27, %weight.143, %40, %489, %490, %491, %36, %492, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.31 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%487, %493), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.145 : Tensor = prim::GetAttr[name="weight"](%w2.7)
  %496 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %497 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %498 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %499 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %out.7 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.31, %weight.145, %40, %496, %497, %498, %36, %499, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %501 : int[] = prim::ListConstruct(%477, %478), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3
  %502 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.7, %501), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %503 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %504 : Tensor?[] = prim::ListConstruct(%top_x.7, %idx.7), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %505 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%503, %504), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.13 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%502, %505), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.15 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.13, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.9 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.7, %44, %top_x.7, %current_hidden_states.15, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %509 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %25), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %510 : Tensor[] = aten::where(%509), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.9 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.9 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%510), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %513 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %514 : Tensor?[] = prim::ListConstruct(%40, %top_x.9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %515 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%513, %514), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %516 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.17 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%515, %516), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.9 : __torch__.torch.nn.modules.conv.___torch_mangle_19.Conv2d = prim::GetAttr[name="w2"](%_4)
  %w3.9 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="w3"](%_4)
  %w1.9 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="w1"](%_4)
  %521 : int = aten::size(%hidden_states.17, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %522 : int = aten::size(%hidden_states.17, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %523 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4
  %input.33 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.17, %523), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.147 : Tensor = prim::GetAttr[name="weight"](%w1.9)
  %526 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %527 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %528 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %529 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %input.35 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.33, %weight.147, %40, %526, %527, %528, %36, %529, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %531 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.149 : Tensor = prim::GetAttr[name="weight"](%w3.9)
  %533 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %534 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %535 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %536 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %537 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.33, %weight.149, %40, %533, %534, %535, %36, %536, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.37 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%531, %537), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.151 : Tensor = prim::GetAttr[name="weight"](%w2.9)
  %540 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %541 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %542 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %543 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %out.9 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.37, %weight.151, %40, %540, %541, %542, %36, %543, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %545 : int[] = prim::ListConstruct(%521, %522), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4
  %546 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.9, %545), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %547 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %548 : Tensor?[] = prim::ListConstruct(%top_x.9, %idx.9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %549 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%547, %548), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.17 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%546, %549), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.19 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.17, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.11 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.9, %44, %top_x.9, %current_hidden_states.19, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %553 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %37), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %554 : Tensor[] = aten::where(%553), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.11 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.11 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%554), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %557 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %558 : Tensor?[] = prim::ListConstruct(%40, %top_x.11), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %559 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%557, %558), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %560 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.19 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%559, %560), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.11 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="w2"](%_5)
  %w3.11 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="w3"](%_5)
  %w1.11 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="w1"](%_5)
  %565 : int = aten::size(%hidden_states.19, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %566 : int = aten::size(%hidden_states.19, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %567 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5
  %input.39 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.19, %567), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.153 : Tensor = prim::GetAttr[name="weight"](%w1.11)
  %570 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %571 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %572 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %573 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %input.41 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.39, %weight.153, %40, %570, %571, %572, %36, %573, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %575 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.155 : Tensor = prim::GetAttr[name="weight"](%w3.11)
  %577 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %578 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %579 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %580 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %581 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.39, %weight.155, %40, %577, %578, %579, %36, %580, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.43 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%575, %581), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.157 : Tensor = prim::GetAttr[name="weight"](%w2.11)
  %584 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %585 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %586 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %587 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %out.11 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.43, %weight.157, %40, %584, %585, %586, %36, %587, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %589 : int[] = prim::ListConstruct(%565, %566), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5
  %590 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.11, %589), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %591 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %592 : Tensor?[] = prim::ListConstruct(%top_x.11, %idx.11), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %593 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%591, %592), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.21 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%590, %593), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.23 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.21, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.13 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.11, %44, %top_x.11, %current_hidden_states.23, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %597 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %12), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %598 : Tensor[] = aten::where(%597), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.13 : Long(64, strides=[1], requires_grad=0, device=cpu), %top_x.13 : Long(64, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%598), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %601 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %602 : Tensor?[] = prim::ListConstruct(%40, %top_x.13), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %603 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::index(%601, %602), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %604 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.21 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%603, %604), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.13 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="w2"](%_6)
  %w3.13 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="w3"](%_6)
  %w1.13 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="w1"](%_6)
  %609 : int = aten::size(%hidden_states.21, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %610 : int = aten::size(%hidden_states.21, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %611 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6
  %input.45 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.21, %611), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.159 : Tensor = prim::GetAttr[name="weight"](%w1.13)
  %614 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %615 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %616 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %617 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %input.47 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.45, %weight.159, %40, %614, %615, %616, %36, %617, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %619 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.47), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.161 : Tensor = prim::GetAttr[name="weight"](%w3.13)
  %621 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %622 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %623 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %624 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %625 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.45, %weight.161, %40, %621, %622, %623, %36, %624, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.49 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%619, %625), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.163 : Tensor = prim::GetAttr[name="weight"](%w2.13)
  %628 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %629 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %630 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %631 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %out.13 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.49, %weight.163, %40, %628, %629, %630, %36, %631, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %633 : int[] = prim::ListConstruct(%609, %610), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6
  %634 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.13, %633), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %635 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %636 : Tensor?[] = prim::ListConstruct(%top_x.13, %idx.13), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %637 : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%635, %636), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.25 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%634, %637), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.27 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.25, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.15 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.13, %44, %top_x.13, %current_hidden_states.27, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %641 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %13), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %642 : Tensor[] = aten::where(%641), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.15 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.15 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%642), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %645 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %646 : Tensor?[] = prim::ListConstruct(%40, %top_x.15), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %647 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%645, %646), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %648 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.23 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%647, %648), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.15 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="w2"](%_7)
  %w3.15 : __torch__.torch.nn.modules.conv.___torch_mangle_32.Conv2d = prim::GetAttr[name="w3"](%_7)
  %w1.15 : __torch__.torch.nn.modules.conv.___torch_mangle_30.Conv2d = prim::GetAttr[name="w1"](%_7)
  %653 : int = aten::size(%hidden_states.23, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %654 : int = aten::size(%hidden_states.23, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %655 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7
  %input.51 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.23, %655), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.165 : Tensor = prim::GetAttr[name="weight"](%w1.15)
  %658 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %659 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %660 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %661 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %input.53 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.51, %weight.165, %40, %658, %659, %660, %36, %661, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %663 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.53), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.167 : Tensor = prim::GetAttr[name="weight"](%w3.15)
  %665 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %666 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %667 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %668 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %669 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.51, %weight.167, %40, %665, %666, %667, %36, %668, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.55 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%663, %669), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.169 : Tensor = prim::GetAttr[name="weight"](%w2.15)
  %672 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %673 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %674 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %675 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %out.15 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.55, %weight.169, %40, %672, %673, %674, %36, %675, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %677 : int[] = prim::ListConstruct(%653, %654), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7
  %678 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.15, %677), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %679 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %680 : Tensor?[] = prim::ListConstruct(%top_x.15, %idx.15), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %681 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%679, %680), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.29 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%678, %681), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.31 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.29, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.17 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.15, %44, %top_x.15, %current_hidden_states.31, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %685 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %686 : Tensor[] = aten::where(%685), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.17 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.17 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%686), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %689 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %690 : Tensor?[] = prim::ListConstruct(%40, %top_x.17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %691 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%689, %690), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %692 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.25 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%691, %692), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.17 : __torch__.torch.nn.modules.conv.___torch_mangle_35.Conv2d = prim::GetAttr[name="w2"](%_8)
  %w3.17 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="w3"](%_8)
  %w1.17 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="w1"](%_8)
  %697 : int = aten::size(%hidden_states.25, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %698 : int = aten::size(%hidden_states.25, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %699 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8
  %input.57 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.25, %699), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.171 : Tensor = prim::GetAttr[name="weight"](%w1.17)
  %702 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %703 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %704 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %705 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %input.59 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.57, %weight.171, %40, %702, %703, %704, %36, %705, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %707 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.59), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.173 : Tensor = prim::GetAttr[name="weight"](%w3.17)
  %709 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %710 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %711 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %712 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %713 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.57, %weight.173, %40, %709, %710, %711, %36, %712, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.61 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%707, %713), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.175 : Tensor = prim::GetAttr[name="weight"](%w2.17)
  %716 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %717 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %718 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %719 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %out.17 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.61, %weight.175, %40, %716, %717, %718, %36, %719, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %721 : int[] = prim::ListConstruct(%697, %698), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8
  %722 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.17, %721), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %723 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %724 : Tensor?[] = prim::ListConstruct(%top_x.17, %idx.17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %725 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%723, %724), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.33 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%722, %725), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.35 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.33, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.19 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.17, %44, %top_x.17, %current_hidden_states.35, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %729 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %14), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %730 : Tensor[] = aten::where(%729), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.19 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.19 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%730), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %733 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %734 : Tensor?[] = prim::ListConstruct(%40, %top_x.19), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %735 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%733, %734), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %736 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.27 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%735, %736), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.19 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="w2"](%_9)
  %w3.19 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="w3"](%_9)
  %w1.19 : __torch__.torch.nn.modules.conv.___torch_mangle_38.Conv2d = prim::GetAttr[name="w1"](%_9)
  %741 : int = aten::size(%hidden_states.27, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %742 : int = aten::size(%hidden_states.27, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %743 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9
  %input.63 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.27, %743), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.177 : Tensor = prim::GetAttr[name="weight"](%w1.19)
  %746 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %747 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %748 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %749 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %input.65 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.63, %weight.177, %40, %746, %747, %748, %36, %749, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %751 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.65), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.179 : Tensor = prim::GetAttr[name="weight"](%w3.19)
  %753 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %754 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %755 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %756 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %757 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.63, %weight.179, %40, %753, %754, %755, %36, %756, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.67 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%751, %757), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.181 : Tensor = prim::GetAttr[name="weight"](%w2.19)
  %760 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %761 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %762 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %763 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %out.19 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.67, %weight.181, %40, %760, %761, %762, %36, %763, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %765 : int[] = prim::ListConstruct(%741, %742), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9
  %766 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.19, %765), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %767 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %768 : Tensor?[] = prim::ListConstruct(%top_x.19, %idx.19), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %769 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%767, %768), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.37 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%766, %769), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.39 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.37, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.21 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.19, %44, %top_x.19, %current_hidden_states.39, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %773 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %15), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %774 : Tensor[] = aten::where(%773), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.21 : Long(64, strides=[1], requires_grad=0, device=cpu), %top_x.21 : Long(64, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%774), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %777 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %778 : Tensor?[] = prim::ListConstruct(%40, %top_x.21), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %779 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::index(%777, %778), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %780 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.29 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%779, %780), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.21 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="w2"](%_10)
  %w3.21 : __torch__.torch.nn.modules.conv.___torch_mangle_44.Conv2d = prim::GetAttr[name="w3"](%_10)
  %w1.21 : __torch__.torch.nn.modules.conv.___torch_mangle_42.Conv2d = prim::GetAttr[name="w1"](%_10)
  %785 : int = aten::size(%hidden_states.29, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %786 : int = aten::size(%hidden_states.29, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %787 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10
  %input.69 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.29, %787), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.183 : Tensor = prim::GetAttr[name="weight"](%w1.21)
  %790 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %791 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %792 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %793 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %input.71 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.69, %weight.183, %40, %790, %791, %792, %36, %793, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %795 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.71), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.185 : Tensor = prim::GetAttr[name="weight"](%w3.21)
  %797 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %798 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %799 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %800 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %801 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.69, %weight.185, %40, %797, %798, %799, %36, %800, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.73 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%795, %801), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.187 : Tensor = prim::GetAttr[name="weight"](%w2.21)
  %804 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %805 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %806 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %807 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %out.21 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.73, %weight.187, %40, %804, %805, %806, %36, %807, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %809 : int[] = prim::ListConstruct(%785, %786), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10
  %810 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.21, %809), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %811 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %812 : Tensor?[] = prim::ListConstruct(%top_x.21, %idx.21), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %813 : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%811, %812), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.41 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%810, %813), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.43 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.41, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.23 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.21, %44, %top_x.21, %current_hidden_states.43, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %817 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %16), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %818 : Tensor[] = aten::where(%817), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.23 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.23 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%818), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %821 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %822 : Tensor?[] = prim::ListConstruct(%40, %top_x.23), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %823 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%821, %822), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %824 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.31 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%823, %824), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.23 : __torch__.torch.nn.modules.conv.___torch_mangle_47.Conv2d = prim::GetAttr[name="w2"](%_11)
  %w3.23 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="w3"](%_11)
  %w1.23 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="w1"](%_11)
  %829 : int = aten::size(%hidden_states.31, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %830 : int = aten::size(%hidden_states.31, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %831 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11
  %input.75 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.31, %831), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.189 : Tensor = prim::GetAttr[name="weight"](%w1.23)
  %834 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %835 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %836 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %837 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %input.77 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.75, %weight.189, %40, %834, %835, %836, %36, %837, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %839 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.77), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.191 : Tensor = prim::GetAttr[name="weight"](%w3.23)
  %841 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %842 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %843 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %844 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %845 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.75, %weight.191, %40, %841, %842, %843, %36, %844, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.79 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%839, %845), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.193 : Tensor = prim::GetAttr[name="weight"](%w2.23)
  %848 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %849 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %850 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %851 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %out.23 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.79, %weight.193, %40, %848, %849, %850, %36, %851, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %853 : int[] = prim::ListConstruct(%829, %830), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11
  %854 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.23, %853), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %855 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %856 : Tensor?[] = prim::ListConstruct(%top_x.23, %idx.23), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %857 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%855, %856), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.45 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%854, %857), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.47 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.45, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.25 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.23, %44, %top_x.23, %current_hidden_states.47, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %861 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %862 : Tensor[] = aten::where(%861), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.25 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.25 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%862), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %865 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %866 : Tensor?[] = prim::ListConstruct(%40, %top_x.25), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %867 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%865, %866), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %868 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.33 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%867, %868), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.25 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="w2"](%_12)
  %w3.25 : __torch__.torch.nn.modules.conv.___torch_mangle_52.Conv2d = prim::GetAttr[name="w3"](%_12)
  %w1.25 : __torch__.torch.nn.modules.conv.___torch_mangle_50.Conv2d = prim::GetAttr[name="w1"](%_12)
  %873 : int = aten::size(%hidden_states.33, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %874 : int = aten::size(%hidden_states.33, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %875 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12
  %input.81 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.33, %875), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.195 : Tensor = prim::GetAttr[name="weight"](%w1.25)
  %878 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %879 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %880 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %881 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %input.83 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.81, %weight.195, %40, %878, %879, %880, %36, %881, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %883 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.83), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.197 : Tensor = prim::GetAttr[name="weight"](%w3.25)
  %885 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %886 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %887 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %888 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %889 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.81, %weight.197, %40, %885, %886, %887, %36, %888, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.85 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%883, %889), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.199 : Tensor = prim::GetAttr[name="weight"](%w2.25)
  %892 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %893 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %894 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %895 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %out.25 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.85, %weight.199, %40, %892, %893, %894, %36, %895, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %897 : int[] = prim::ListConstruct(%873, %874), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12
  %898 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.25, %897), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %899 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %900 : Tensor?[] = prim::ListConstruct(%top_x.25, %idx.25), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %901 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%899, %900), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.49 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%898, %901), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.51 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.49, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.27 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.25, %44, %top_x.25, %current_hidden_states.51, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %905 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %18), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %906 : Tensor[] = aten::where(%905), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.27 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.27 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%906), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %909 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %910 : Tensor?[] = prim::ListConstruct(%40, %top_x.27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %911 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%909, %910), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %912 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.35 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%911, %912), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.27 : __torch__.torch.nn.modules.conv.___torch_mangle_55.Conv2d = prim::GetAttr[name="w2"](%_13)
  %w3.27 : __torch__.torch.nn.modules.conv.___torch_mangle_56.Conv2d = prim::GetAttr[name="w3"](%_13)
  %w1.27 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="w1"](%_13)
  %917 : int = aten::size(%hidden_states.35, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %918 : int = aten::size(%hidden_states.35, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %919 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13
  %input.87 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.35, %919), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.201 : Tensor = prim::GetAttr[name="weight"](%w1.27)
  %922 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %923 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %924 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %925 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %input.89 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.87, %weight.201, %40, %922, %923, %924, %36, %925, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %927 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.89), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.203 : Tensor = prim::GetAttr[name="weight"](%w3.27)
  %929 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %930 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %931 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %932 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %933 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.87, %weight.203, %40, %929, %930, %931, %36, %932, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.91 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%927, %933), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.205 : Tensor = prim::GetAttr[name="weight"](%w2.27)
  %936 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %937 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %938 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %939 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %out.27 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.91, %weight.205, %40, %936, %937, %938, %36, %939, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %941 : int[] = prim::ListConstruct(%917, %918), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13
  %942 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.27, %941), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %943 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %944 : Tensor?[] = prim::ListConstruct(%top_x.27, %idx.27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %945 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%943, %944), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.53 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%942, %945), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.55 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.53, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.29 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.27, %44, %top_x.27, %current_hidden_states.55, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %949 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %19), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %950 : Tensor[] = aten::where(%949), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.29 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.29 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%950), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %953 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %954 : Tensor?[] = prim::ListConstruct(%40, %top_x.29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %955 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%953, %954), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %956 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.37 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%955, %956), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.29 : __torch__.torch.nn.modules.conv.___torch_mangle_59.Conv2d = prim::GetAttr[name="w2"](%_14)
  %w3.29 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="w3"](%_14)
  %w1.29 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="w1"](%_14)
  %961 : int = aten::size(%hidden_states.37, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %962 : int = aten::size(%hidden_states.37, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %963 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14
  %input.93 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.37, %963), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.207 : Tensor = prim::GetAttr[name="weight"](%w1.29)
  %966 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %967 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %968 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %969 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %input.95 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.93, %weight.207, %40, %966, %967, %968, %36, %969, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %971 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.95), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.209 : Tensor = prim::GetAttr[name="weight"](%w3.29)
  %973 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %974 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %975 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %976 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %977 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.93, %weight.209, %40, %973, %974, %975, %36, %976, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.97 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%971, %977), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.211 : Tensor = prim::GetAttr[name="weight"](%w2.29)
  %980 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %981 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %982 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %983 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %out.29 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.97, %weight.211, %40, %980, %981, %982, %36, %983, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %985 : int[] = prim::ListConstruct(%961, %962), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14
  %986 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.29, %985), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %987 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %988 : Tensor?[] = prim::ListConstruct(%top_x.29, %idx.29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %989 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%987, %988), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.57 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%986, %989), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.59 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.57, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.31 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.29, %44, %top_x.29, %current_hidden_states.59, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %993 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %20), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %994 : Tensor[] = aten::where(%993), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%994), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %997 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %998 : Tensor?[] = prim::ListConstruct(%40, %top_x), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %999 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%997, %998), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %1000 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%999, %1000), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2 : __torch__.torch.nn.modules.conv.___torch_mangle_63.Conv2d = prim::GetAttr[name="w2"](%_15)
  %w3 : __torch__.torch.nn.modules.conv.___torch_mangle_64.Conv2d = prim::GetAttr[name="w3"](%_15)
  %w1 : __torch__.torch.nn.modules.conv.___torch_mangle_62.Conv2d = prim::GetAttr[name="w1"](%_15)
  %1005 : int = aten::size(%hidden_states, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %1006 : int = aten::size(%hidden_states, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %1007 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15
  %input.99 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states, %1007), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.213 : Tensor = prim::GetAttr[name="weight"](%w1)
  %1010 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %1011 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %1012 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %1013 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %input.101 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.99, %weight.213, %40, %1010, %1011, %1012, %36, %1013, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %1015 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.101), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.215 : Tensor = prim::GetAttr[name="weight"](%w3)
  %1017 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1018 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1019 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1020 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1021 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.99, %weight.215, %40, %1017, %1018, %1019, %36, %1020, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%1015, %1021), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight : Tensor = prim::GetAttr[name="weight"](%w2)
  %1024 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %1025 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %1026 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %1027 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %out : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input, %weight, %40, %1024, %1025, %1026, %36, %1027, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %1029 : int[] = prim::ListConstruct(%1005, %1006), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15
  %1030 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out, %1029), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %1031 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %1032 : Tensor?[] = prim::ListConstruct(%top_x, %idx), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %1033 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%1031, %1032), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.61 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%1030, %1033), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.61, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.31, %44, %top_x, %current_hidden_states, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %1037 : int[] = prim::ListConstruct(%280, %282, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %1038 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::reshape(%final_hidden_states, %1037), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:664:0
  %1039 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::add(%input.5, %1038, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1300:0
  return (%1039)








  (Pdb) print(traced_model.inlined_graph)
graph(%self.1 : __torch__.PrefillWrapper,
      %hidden_states.1 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=0, device=cpu),
      %position_ids.1 : Long(64, strides=[1], requires_grad=0, device=cpu),
      %causal_mask : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu),
      %current_pos.1 : Long(1, strides=[1], requires_grad=0, device=cpu)):
  %model.1 : __torch__.anemll.models.phimoe_model.PhimoeForCausalLM = prim::GetAttr[name="model"](%self.1)
  %model : __torch__.anemll.models.phimoe_model.PhimoeModel = prim::GetAttr[name="model"](%model.1)
  %8 : int = prim::Constant[value=16](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:604:0
  %9 : float = prim::Constant[value=0.02](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:412:0
  %10 : float = prim::Constant[value=-inf](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:415:0
  %11 : Device = prim::Constant[value="cpu"](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:615:0
  %12 : int = prim::Constant[value=6](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %13 : int = prim::Constant[value=7](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %14 : int = prim::Constant[value=9](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %15 : int = prim::Constant[value=10](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %16 : int = prim::Constant[value=11](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %17 : int = prim::Constant[value=12](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %18 : int = prim::Constant[value=13](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %19 : int = prim::Constant[value=14](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %20 : int = prim::Constant[value=15](), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %21 : str = prim::Constant[value="bhqk,bhkd->bhqd"](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/functional.py:402:0
  %22 : Double(requires_grad=0, device=cpu) = prim::Constant[value={11.3137}](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1031:0
  %23 : str = prim::Constant[value="bhqd,bhkd->bhqk"](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/functional.py:402:0
  %24 : int = prim::Constant[value=-2](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %25 : int = prim::Constant[value=4](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1066:0
  %26 : int = prim::Constant[value=512](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1004:0
  %27 : int = prim::Constant[value=-1](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:935:0
  %28 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/_tensor.py:1061:0
  %29 : int = prim::Constant[value=8](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:772:0
  %30 : int = prim::Constant[value=3](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:771:0
  %31 : int = prim::Constant[value=32](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:771:0
  %32 : int = prim::Constant[value=2](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:763:0
  %33 : int = prim::Constant[value=4096](), scope: __module.model.model/__module.model.model.layers.0.input_layernorm # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2900:0
  %34 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model.model/__module.model.model.layers.0.input_layernorm # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2900:0
  %35 : bool = prim::Constant[value=1](), scope: __module.model.model/__module.model.model.layers.0.input_layernorm # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2900:0
  %36 : bool = prim::Constant[value=0](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1226:0
  %37 : int = prim::Constant[value=5](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1226:0
  %38 : Float(1, 131072, 128, strides=[16777216, 128, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1216:0
  %39 : int = prim::Constant[value=128](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1215:0
  %40 : NoneType = prim::Constant(), scope: __module.model.model
  %41 : int = prim::Constant[value=1](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1215:0
  %42 : int = prim::Constant[value=9223372036854775807](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1215:0
  %43 : Float(1, 131072, 128, strides=[16777216, 128, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1215:0
  %44 : int = prim::Constant[value=0](), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1214:0
  %layers : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%model)
  %_0 : __torch__.anemll.models.phimoe_model.PhimoeDecoderLayer = prim::GetAttr[name="0"](%layers)
  %block_sparse_moe : __torch__.anemll.models.phimoe_model.PhimoeSparseMoeBlock = prim::GetAttr[name="block_sparse_moe"](%_0)
  %layers.11 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%model)
  %_0.11 : __torch__.anemll.models.phimoe_model.PhimoeDecoderLayer = prim::GetAttr[name="0"](%layers.11)
  %post_attention_layernorm : __torch__.torch.nn.modules.normalization.___torch_mangle_66.LayerNorm = prim::GetAttr[name="post_attention_layernorm"](%_0.11)
  %layers.9 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%model)
  %_0.9 : __torch__.anemll.models.phimoe_model.PhimoeDecoderLayer = prim::GetAttr[name="0"](%layers.9)
  %self_attn : __torch__.anemll.models.phimoe_model.PhimoeAttention = prim::GetAttr[name="self_attn"](%_0.9)
  %o_proj : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="o_proj"](%self_attn)
  %kv_cache_0 : Tensor = prim::GetAttr[name="kv_cache_0"](%model)
  %layers.7 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%model)
  %_0.7 : __torch__.anemll.models.phimoe_model.PhimoeDecoderLayer = prim::GetAttr[name="0"](%layers.7)
  %self_attn.5 : __torch__.anemll.models.phimoe_model.PhimoeAttention = prim::GetAttr[name="self_attn"](%_0.7)
  %v_proj : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="v_proj"](%self_attn.5)
  %layers.5 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%model)
  %_0.5 : __torch__.anemll.models.phimoe_model.PhimoeDecoderLayer = prim::GetAttr[name="0"](%layers.5)
  %self_attn.3 : __torch__.anemll.models.phimoe_model.PhimoeAttention = prim::GetAttr[name="self_attn"](%_0.5)
  %k_proj : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="k_proj"](%self_attn.3)
  %layers.3 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%model)
  %_0.3 : __torch__.anemll.models.phimoe_model.PhimoeDecoderLayer = prim::GetAttr[name="0"](%layers.3)
  %self_attn.1 : __torch__.anemll.models.phimoe_model.PhimoeAttention = prim::GetAttr[name="self_attn"](%_0.3)
  %q_proj : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="q_proj"](%self_attn.1)
  %layers.1 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%model)
  %_0.1 : __torch__.anemll.models.phimoe_model.PhimoeDecoderLayer = prim::GetAttr[name="0"](%layers.1)
  %input_layernorm : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="input_layernorm"](%_0.1)
  %71 : int = aten::size(%position_ids.1, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1214:0
  %72 : Float(1, 131072, 128, strides=[16777216, 128, 1], requires_grad=0, device=cpu) = aten::slice(%43, %44, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1215:0
  %73 : Tensor?[] = prim::ListConstruct(%40, %position_ids.1), scope: __module.model.model
  %74 : Float(1, 64, 128, strides=[8192, 128, 1], requires_grad=0, device=cpu) = aten::index(%72, %73), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1215:0
  %75 : int[] = prim::ListConstruct(%41, %71, %41, %39), scope: __module.model.model
  %cos.1 : Float(1, 64, 1, 128, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::view(%74, %75), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1215:0
  %77 : Float(1, 131072, 128, strides=[16777216, 128, 1], requires_grad=0, device=cpu) = aten::slice(%38, %44, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1216:0
  %78 : Tensor?[] = prim::ListConstruct(%40, %position_ids.1), scope: __module.model.model
  %79 : Float(1, 64, 128, strides=[8192, 128, 1], requires_grad=0, device=cpu) = aten::index(%77, %78), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1216:0
  %80 : int[] = prim::ListConstruct(%41, %71, %41, %39), scope: __module.model.model
  %sin.1 : Float(1, 64, 1, 128, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::view(%79, %80), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1216:0
  %cos.3 : Half(1, 64, 1, 128, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::to(%cos.1, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1226:0
  %sin.3 : Half(1, 64, 1, 128, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::to(%sin.1, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1226:0
  %bias.11 : Tensor = prim::GetAttr[name="bias"](%input_layernorm)
  %weight.109 : Tensor = prim::GetAttr[name="weight"](%input_layernorm)
  %86 : int[] = prim::ListConstruct(%33), scope: __module.model.model/__module.model.model.layers.0.input_layernorm
  %hidden_states.3 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::layer_norm(%hidden_states.1, %86, %weight.109, %bias.11, %34, %35), scope: __module.model.model/__module.model.model.layers.0.input_layernorm # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2900:0
  %88 : int = aten::size(%hidden_states.3, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:754:0
  %89 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::resolve_conj(%current_pos.1), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/_tensor_str.py:261:0
  %current_pos : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::resolve_neg(%89), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/_tensor_str.py:261:0
  %91 : int = aten::Int(%current_pos), scope: __module.model.model
  %92 : int = aten::Int(%current_pos), scope: __module.model.model
  %93 : int[] = prim::ListConstruct(%44, %32, %41), scope: __module.model.model
  %94 : Half(1, 4096, 64, strides=[262144, 1, 4096], requires_grad=1, device=cpu) = aten::permute(%hidden_states.3, %93), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:763:0
  %95 : Half(1, 4096, 1, 64, strides=[262144, 1, 262144, 4096], requires_grad=1, device=cpu) = aten::unsqueeze(%94, %32), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:763:0
  %input.1 : Half(1, 4096, 1, 64, strides=[262144, 1, 262144, 4096], requires_grad=1, device=cpu) = aten::to(%95, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:763:0
  %bias.13 : Tensor = prim::GetAttr[name="bias"](%q_proj)
  %weight.111 : Tensor = prim::GetAttr[name="weight"](%q_proj)
  %99 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.self_attn.q_proj
  %100 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.self_attn.q_proj
  %101 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.self_attn.q_proj
  %102 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.self_attn.q_proj
  %query_states.1 : Half(1, 4096, 1, 64, strides=[262144, 1, 262144, 4096], requires_grad=0, device=cpu) = aten::_convolution(%input.1, %weight.111, %bias.13, %99, %100, %101, %36, %102, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.self_attn.q_proj # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %bias.15 : Tensor = prim::GetAttr[name="bias"](%k_proj)
  %weight.113 : Tensor = prim::GetAttr[name="weight"](%k_proj)
  %106 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.self_attn.k_proj
  %107 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.self_attn.k_proj
  %108 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.self_attn.k_proj
  %109 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.self_attn.k_proj
  %key_states.1 : Half(1, 1024, 1, 64, strides=[65536, 1, 65536, 1024], requires_grad=0, device=cpu) = aten::_convolution(%input.1, %weight.113, %bias.15, %106, %107, %108, %36, %109, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.self_attn.k_proj # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %bias.17 : Tensor = prim::GetAttr[name="bias"](%v_proj)
  %weight.115 : Tensor = prim::GetAttr[name="weight"](%v_proj)
  %113 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.self_attn.v_proj
  %114 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.self_attn.v_proj
  %115 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.self_attn.v_proj
  %116 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.self_attn.v_proj
  %value_states.1 : Half(1, 1024, 1, 64, strides=[65536, 1, 65536, 1024], requires_grad=0, device=cpu) = aten::_convolution(%input.1, %weight.115, %bias.17, %113, %114, %115, %36, %116, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.self_attn.v_proj # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %118 : int[] = prim::ListConstruct(%41, %31, %39, %88), scope: __module.model.model
  %119 : Half(1, 32, 128, 64, strides=[4096, 128, 1, 4096], requires_grad=1, device=cpu) = aten::view(%query_states.1, %118), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:771:0
  %120 : int[] = prim::ListConstruct(%44, %41, %30, %32), scope: __module.model.model
  %x.1 : Half(1, 32, 64, 128, strides=[4096, 128, 4096, 1], requires_grad=1, device=cpu) = aten::permute(%119, %120), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:771:0
  %122 : int[] = prim::ListConstruct(%41, %29, %39, %88), scope: __module.model.model
  %123 : Half(1, 8, 128, 64, strides=[1024, 128, 1, 1024], requires_grad=1, device=cpu) = aten::view(%key_states.1, %122), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:772:0
  %124 : int[] = prim::ListConstruct(%44, %41, %30, %32), scope: __module.model.model
  %x.5 : Half(1, 8, 64, 128, strides=[1024, 128, 1024, 1], requires_grad=1, device=cpu) = aten::permute(%123, %124), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:772:0
  %126 : int[] = prim::ListConstruct(%41, %29, %39, %88), scope: __module.model.model
  %127 : Half(1, 8, 128, 64, strides=[1024, 128, 1, 1024], requires_grad=1, device=cpu) = aten::view(%value_states.1, %126), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:773:0
  %128 : int[] = prim::ListConstruct(%44, %41, %30, %32), scope: __module.model.model
  %value_states.3 : Half(1, 8, 64, 128, strides=[1024, 128, 1024, 1], requires_grad=1, device=cpu) = aten::permute(%127, %128), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:773:0
  %130 : int[] = prim::ListConstruct(%44, %32, %41, %30), scope: __module.model.model
  %cos.5 : Half(1, 1, 64, 128, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::permute(%cos.3, %130), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:778:0
  %132 : int[] = prim::ListConstruct(%44, %32, %41, %30), scope: __module.model.model
  %sin.5 : Half(1, 1, 64, 128, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::permute(%sin.3, %132), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:779:0
  %x.3 : Half(1, 32, 64, 128, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::contiguous(%x.1, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:916:0
  %135 : int = aten::size(%x.3, %30), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:917:0
  %136 : Long(device=cpu) = prim::NumToTensor(%135), scope: __module.model.model
  %half_dim.1 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%136, %28), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/_tensor.py:1061:0
  %138 : int = aten::Int(%half_dim.1), scope: __module.model.model
  %139 : int = aten::Int(%half_dim.1), scope: __module.model.model
  %140 : int = aten::Int(%half_dim.1), scope: __module.model.model
  %141 : int = aten::Int(%half_dim.1), scope: __module.model.model
  %x1.1 : Half(1, 32, 64, 64, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::slice(%x.3, %30, %44, %141, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:919:0
  %x2.1 : Half(1, 32, 64, 64, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::slice(%x.3, %30, %140, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:920:0
  %cos.7 : Half(1, 1, 64, 64, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%cos.5, %30, %44, %139, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:928:0
  %sin.7 : Half(1, 1, 64, 64, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%sin.5, %30, %44, %138, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:929:0
  %146 : Half(1, 32, 64, 64, strides=[131072, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x1.1, %cos.7), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:936:0
  %147 : Half(1, 32, 64, 64, strides=[131072, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x2.1, %sin.7), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:936:0
  %148 : Half(1, 32, 64, 64, strides=[131072, 4096, 64, 1], requires_grad=1, device=cpu) = aten::sub(%146, %147, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:936:0
  %149 : Half(1, 32, 64, 64, strides=[131072, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x2.1, %cos.7), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:937:0
  %150 : Half(1, 32, 64, 64, strides=[131072, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x1.1, %sin.7), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:937:0
  %151 : Half(1, 32, 64, 64, strides=[131072, 4096, 64, 1], requires_grad=1, device=cpu) = aten::add(%149, %150, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:937:0
  %152 : Tensor[] = prim::ListConstruct(%148, %151), scope: __module.model.model
  %rotated.1 : Half(1, 32, 64, 128, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::cat(%152, %27), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:935:0
  %query_states.3 : Half(1, 32, 64, 128, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::to(%rotated.1, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:941:0
  %x.7 : Half(1, 8, 64, 128, strides=[65536, 8192, 128, 1], requires_grad=1, device=cpu) = aten::contiguous(%x.5, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:916:0
  %156 : int = aten::size(%x.7, %30), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:917:0
  %157 : Long(device=cpu) = prim::NumToTensor(%156), scope: __module.model.model
  %half_dim : Long(requires_grad=0, device=cpu) = aten::floor_divide(%157, %28), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/_tensor.py:1061:0
  %159 : int = aten::Int(%half_dim), scope: __module.model.model
  %160 : int = aten::Int(%half_dim), scope: __module.model.model
  %161 : int = aten::Int(%half_dim), scope: __module.model.model
  %162 : int = aten::Int(%half_dim), scope: __module.model.model
  %x1 : Half(1, 8, 64, 64, strides=[65536, 8192, 128, 1], requires_grad=1, device=cpu) = aten::slice(%x.7, %30, %44, %162, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:919:0
  %x2 : Half(1, 8, 64, 64, strides=[65536, 8192, 128, 1], requires_grad=1, device=cpu) = aten::slice(%x.7, %30, %161, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:920:0
  %cos : Half(1, 1, 64, 64, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%cos.5, %30, %44, %160, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:928:0
  %sin : Half(1, 1, 64, 64, strides=[8192, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%sin.5, %30, %44, %159, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:929:0
  %167 : Half(1, 8, 64, 64, strides=[32768, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x1, %cos), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:936:0
  %168 : Half(1, 8, 64, 64, strides=[32768, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x2, %sin), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:936:0
  %169 : Half(1, 8, 64, 64, strides=[32768, 4096, 64, 1], requires_grad=1, device=cpu) = aten::sub(%167, %168, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:936:0
  %170 : Half(1, 8, 64, 64, strides=[32768, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x2, %cos), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:937:0
  %171 : Half(1, 8, 64, 64, strides=[32768, 4096, 64, 1], requires_grad=1, device=cpu) = aten::mul(%x1, %sin), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:937:0
  %172 : Half(1, 8, 64, 64, strides=[32768, 4096, 64, 1], requires_grad=1, device=cpu) = aten::add(%170, %171, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:937:0
  %173 : Tensor[] = prim::ListConstruct(%169, %172), scope: __module.model.model
  %rotated : Half(1, 8, 64, 128, strides=[65536, 8192, 128, 1], requires_grad=1, device=cpu) = aten::cat(%173, %27), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:935:0
  %key_states.3 : Half(1, 8, 64, 128, strides=[65536, 8192, 128, 1], requires_grad=1, device=cpu) = aten::to(%rotated, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:941:0
  %query_states : Half(1, 32, 64, 128, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::to(%query_states.3, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:784:0
  %key_states.5 : Half(1, 8, 64, 128, strides=[65536, 8192, 128, 1], requires_grad=1, device=cpu) = aten::to(%key_states.3, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:784:0
  %value_states.5 : Half(1, 8, 64, 128, strides=[1024, 128, 1024, 1], requires_grad=1, device=cpu) = aten::to(%value_states.3, %37, %36, %36, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:784:0
  %179 : int = aten::size(%key_states.5, %32), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1277:0
  %seq_length : Long(device=cpu) = prim::NumToTensor(%179), scope: __module.model.model
  %181 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::add(%current_pos, %seq_length, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1278:0
  %182 : int = aten::Int(%181), scope: __module.model.model
  %183 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=0, device=cpu) = aten::slice(%kv_cache_0, %44, %44, %41, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1278:0
  %184 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=0, device=cpu) = aten::slice(%183, %41, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1278:0
  %185 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=0, device=cpu) = aten::slice(%184, %32, %92, %182, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1278:0
  %186 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=0, device=cpu) = aten::slice(%185, %30, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1278:0
  %187 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::copy_(%186, %key_states.5, %36), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1278:0
  %188 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::add(%current_pos, %seq_length, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %189 : int = aten::Int(%188), scope: __module.model.model
  %190 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%kv_cache_0, %44, %32, %30, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %191 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%190, %41, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %192 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%191, %32, %91, %189, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %193 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%192, %30, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %194 : Half(1, 8, 64, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::copy_(%193, %value_states.5, %36), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1279:0
  %195 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%kv_cache_0, %44, %44, %41, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1282:0
  %K_layer_cache.1 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::squeeze(%195, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1282:0
  %197 : Half(1, 8, 512, 128, strides=[524288, 65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%kv_cache_0, %44, %32, %30, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1283:0
  %V_layer_cache : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::squeeze(%197, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1283:0
  %199 : int = aten::size(%hidden_states.3, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:998:0
  %200 : int = aten::size(%hidden_states.3, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:998:0
  %201 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%K_layer_cache.1, %41, %44, %26, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1004:0
  %K_layer_cache : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%201, %32, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1004:0
  %203 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%V_layer_cache, %41, %44, %26, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1005:0
  %x.13 : Half(8, 512, 128, strides=[65536, 128, 1], requires_grad=1, device=cpu) = aten::slice(%203, %32, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1005:0
  %x.9 : Half(8, 1, 512, 128, strides=[65536, 65536, 128, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%K_layer_cache, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1065:0
  %206 : int[] = prim::ListConstruct(%41, %25, %41, %41), scope: __module.model.model
  %x.11 : Half(8, 4, 512, 128, strides=[262144, 65536, 128, 1], requires_grad=1, device=cpu) = aten::repeat(%x.9, %206), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1066:0
  %208 : int = aten::size(%x.11, %24), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %209 : int = aten::size(%x.11, %27), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %210 : int[] = prim::ListConstruct(%41, %27, %208, %209), scope: __module.model.model
  %key_states : Half(1, 32, 512, 128, strides=[2097152, 65536, 128, 1], requires_grad=1, device=cpu) = aten::view(%x.11, %210), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %x.15 : Half(8, 1, 512, 128, strides=[65536, 65536, 128, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%x.13, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1065:0
  %213 : int[] = prim::ListConstruct(%41, %25, %41, %41), scope: __module.model.model
  %x.17 : Half(8, 4, 512, 128, strides=[262144, 65536, 128, 1], requires_grad=1, device=cpu) = aten::repeat(%x.15, %213), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1066:0
  %215 : int = aten::size(%x.17, %24), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %216 : int = aten::size(%x.17, %27), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %217 : int[] = prim::ListConstruct(%41, %27, %215, %216), scope: __module.model.model
  %value_states : Half(1, 32, 512, 128, strides=[2097152, 65536, 128, 1], requires_grad=1, device=cpu) = aten::view(%x.17, %217), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1067:0
  %219 : Tensor[] = prim::ListConstruct(%query_states, %key_states), scope: __module.model.model
  %220 : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::einsum(%23, %219, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/functional.py:402:0
  %attn_weights : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::div(%220, %22), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1031:0
  %222 : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu) = aten::slice(%causal_mask, %44, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %223 : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu) = aten::slice(%222, %41, %44, %42, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %224 : Half(1, 1, 64, 512, strides=[32768, 32768, 512, 1], requires_grad=0, device=cpu) = aten::slice(%223, %32, %44, %26, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %x.19 : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::add(%attn_weights, %224, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1037:0
  %x_max : Half(1, 32, 64, 1, strides=[2048, 64, 1, 1], requires_grad=1, device=cpu), %227 : Long(1, 32, 64, 1, strides=[2048, 64, 1, 1], requires_grad=0, device=cpu) = aten::max(%x.19, %27, %35), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:893:0
  %x : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::sub(%x.19, %x_max, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:894:0
  %exp_x : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::exp(%x), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:895:0
  %230 : int[] = prim::ListConstruct(%27), scope: __module.model.model
  %231 : Half(1, 32, 64, 1, strides=[2048, 64, 1, 1], requires_grad=1, device=cpu) = aten::sum(%exp_x, %230, %35, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:896:0
  %232 : Half(1, 32, 64, 512, strides=[1048576, 32768, 512, 1], requires_grad=1, device=cpu) = aten::div(%exp_x, %231), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:896:0
  %233 : Tensor[] = prim::ListConstruct(%232, %value_states), scope: __module.model.model
  %attn_output.1 : Half(1, 32, 64, 128, strides=[262144, 8192, 128, 1], requires_grad=1, device=cpu) = aten::einsum(%21, %233, %40), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/functional.py:402:0
  %235 : Half(1, 64, 32, 128, strides=[262144, 128, 8192, 1], requires_grad=1, device=cpu) = aten::transpose(%attn_output.1, %41, %32), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1051:0
  %attn_output.3 : Half(1, 64, 32, 128, strides=[262144, 4096, 128, 1], requires_grad=1, device=cpu) = aten::contiguous(%235, %44), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1051:0
  %237 : int[] = prim::ListConstruct(%199, %200, %33), scope: __module.model.model
  %input.3 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::reshape(%attn_output.3, %237), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1052:0
  %bias.19 : Tensor = prim::GetAttr[name="bias"](%o_proj)
  %weight.117 : Tensor = prim::GetAttr[name="weight"](%o_proj)
  %attn_output : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::linear(%input.3, %weight.117, %bias.19), scope: __module.model.model/__module.model.model.layers.0.self_attn.o_proj # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/linear.py:125:0
  %input.5 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::add(%hidden_states.1, %attn_output, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1293:0
  %bias : Tensor = prim::GetAttr[name="bias"](%post_attention_layernorm)
  %weight.119 : Tensor = prim::GetAttr[name="weight"](%post_attention_layernorm)
  %245 : int[] = prim::ListConstruct(%33), scope: __module.model.model/__module.model.model.layers.0.post_attention_layernorm
  %hidden_states.5 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::layer_norm(%input.5, %245, %weight.119, %bias, %34, %35), scope: __module.model.model/__module.model.model.layers.0.post_attention_layernorm # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2900:0
  %experts : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_15 : __torch__.anemll.models.phimoe_model.___torch_mangle_65.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="15"](%experts)
  %experts.29 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_14 : __torch__.anemll.models.phimoe_model.___torch_mangle_61.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="14"](%experts.29)
  %experts.27 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_13 : __torch__.anemll.models.phimoe_model.___torch_mangle_57.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="13"](%experts.27)
  %experts.25 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_12 : __torch__.anemll.models.phimoe_model.___torch_mangle_53.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="12"](%experts.25)
  %experts.23 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_11 : __torch__.anemll.models.phimoe_model.___torch_mangle_49.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="11"](%experts.23)
  %experts.21 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_10 : __torch__.anemll.models.phimoe_model.___torch_mangle_45.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="10"](%experts.21)
  %experts.19 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_9 : __torch__.anemll.models.phimoe_model.___torch_mangle_41.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="9"](%experts.19)
  %experts.17 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_8 : __torch__.anemll.models.phimoe_model.___torch_mangle_37.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="8"](%experts.17)
  %experts.15 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_7 : __torch__.anemll.models.phimoe_model.___torch_mangle_33.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="7"](%experts.15)
  %experts.13 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_6 : __torch__.anemll.models.phimoe_model.___torch_mangle_29.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="6"](%experts.13)
  %experts.11 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_5 : __torch__.anemll.models.phimoe_model.___torch_mangle_25.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="5"](%experts.11)
  %experts.9 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_4 : __torch__.anemll.models.phimoe_model.___torch_mangle_21.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="4"](%experts.9)
  %experts.7 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_3 : __torch__.anemll.models.phimoe_model.___torch_mangle_17.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="3"](%experts.7)
  %experts.5 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_2 : __torch__.anemll.models.phimoe_model.___torch_mangle_13.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="2"](%experts.5)
  %experts.3 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_1 : __torch__.anemll.models.phimoe_model.___torch_mangle_9.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="1"](%experts.3)
  %experts.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="experts"](%block_sparse_moe)
  %_0.13 : __torch__.anemll.models.phimoe_model.PhimoeBlockSparseTop2MLP = prim::GetAttr[name="0"](%experts.1)
  %gate : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="gate"](%block_sparse_moe)
  %280 : int = aten::size(%hidden_states.5, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:593:0
  %batch_size : Long(device=cpu) = prim::NumToTensor(%280), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %282 : int = aten::size(%hidden_states.5, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:593:0
  %sequence_length : Long(device=cpu) = prim::NumToTensor(%282), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %284 : int = aten::size(%hidden_states.5, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:593:0
  %285 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.7 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.5, %285), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:599:0
  %287 : Long(requires_grad=0, device=cpu) = aten::mul(%batch_size, %sequence_length), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:602:0
  %288 : int = aten::Int(%287), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %289 : int[] = prim::ListConstruct(%288, %284, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %input.7 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.7, %289), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:602:0
  %weight.121 : Tensor = prim::GetAttr[name="weight"](%gate)
  %292 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %293 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %294 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %295 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate
  %router_logits : Half(64, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.7, %weight.121, %40, %292, %293, %294, %36, %295, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.gate # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %297 : Long(requires_grad=0, device=cpu) = aten::mul(%batch_size, %sequence_length), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:604:0
  %298 : int = aten::Int(%297), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %299 : int[] = prim::ListConstruct(%298, %8), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %scores : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::view(%router_logits, %299), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:604:0
  %mask_logits_threshold.1 : Half(64, 1, strides=[1, 1], requires_grad=0, device=cpu), %max_ind.1 : Long(64, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::max(%scores, %27, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:410:0
  %303 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::abs(%scores), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:411:0
  %factor.1 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::clamp(%303, %mask_logits_threshold.1, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:411:0
  %305 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::sub(%mask_logits_threshold.1, %scores, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:412:0
  %306 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::div(%305, %factor.1), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:412:0
  %mask_logits_threshold.3 : Bool(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::gt(%306, %9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:412:0
  %masked_gates.1 : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::masked_fill(%scores, %mask_logits_threshold.3, %10), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:415:0
  %masked_gates : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::softmax(%masked_gates.1, %27, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:430:0
  %multiplier_o : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::gather(%masked_gates, %27, %max_ind.1, %36), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:431:0
  %masked_scores : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::scatter(%scores, %27, %max_ind.1, %10), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:455:0
  %mask_logits_threshold.5 : Half(64, 1, strides=[1, 1], requires_grad=0, device=cpu), %max_ind : Long(64, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::max(%masked_scores, %27, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:463:0
  %314 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::abs(%scores), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:464:0
  %factor : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::clamp(%314, %mask_logits_threshold.5, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:464:0
  %316 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::sub(%mask_logits_threshold.5, %scores, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:465:0
  %317 : Half(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::div(%316, %factor), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:465:0
  %mask_logits_threshold : Bool(64, 16, strides=[16, 1], requires_grad=0, device=cpu) = aten::gt(%317, %9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:465:0
  %masked_gates_top2.1 : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::masked_fill(%masked_scores, %mask_logits_threshold, %10), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:468:0
  %masked_gates_top2 : Half(64, 16, strides=[16, 1], requires_grad=1, device=cpu) = aten::softmax(%masked_gates_top2.1, %27, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:484:0
  %multiplier_top2_o : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::gather(%masked_gates_top2, %27, %max_ind, %36), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:485:0
  %322 : Tensor[] = prim::ListConstruct(%multiplier_o, %multiplier_top2_o), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %routing_weights : Half(64, 2, strides=[2, 1], requires_grad=1, device=cpu) = aten::concat(%322, %27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:508:0
  %324 : Tensor[] = prim::ListConstruct(%max_ind.1, %max_ind), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %selected_experts : Long(64, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::concat(%324, %27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:509:0
  %326 : Long(requires_grad=0, device=cpu) = aten::mul(%batch_size, %sequence_length), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:616:0
  %327 : int = aten::Int(%326), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %328 : int[] = prim::ListConstruct(%327, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %final_hidden_states.1 : Half(64, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::zeros(%328, %37, %40, %11, %36), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:615:0
  %330 : Long(64, 2, 16, strides=[32, 16, 1], requires_grad=0, device=cpu) = aten::one_hot(%selected_experts, %8), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:621:0
  %331 : int[] = prim::ListConstruct(%32, %41, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %expert_mask : Long(16, 2, 64, strides=[1, 16, 32], requires_grad=0, device=cpu) = aten::permute(%330, %331), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:621:0
  %333 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %334 : Tensor[] = aten::where(%333), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.1 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.1 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%334), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %337 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %338 : Tensor?[] = prim::ListConstruct(%40, %top_x.1), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %339 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%337, %338), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %340 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.9 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%339, %340), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.1 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="w2"](%_0.13)
  %w3.1 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="w3"](%_0.13)
  %w1.1 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="w1"](%_0.13)
  %345 : int = aten::size(%hidden_states.9, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %346 : int = aten::size(%hidden_states.9, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %347 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0
  %input.9 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.9, %347), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.123 : Tensor = prim::GetAttr[name="weight"](%w1.1)
  %350 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %351 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %352 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %353 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1
  %input.11 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.9, %weight.123, %40, %350, %351, %352, %36, %353, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %355 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.11), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.125 : Tensor = prim::GetAttr[name="weight"](%w3.1)
  %357 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %358 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %359 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %360 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3
  %361 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.9, %weight.125, %40, %357, %358, %359, %36, %360, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.13 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%355, %361), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.127 : Tensor = prim::GetAttr[name="weight"](%w2.1)
  %364 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %365 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %366 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %367 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2
  %out.1 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.13, %weight.127, %40, %364, %365, %366, %36, %367, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0/__module.model.model.layers.0.block_sparse_moe.experts.0.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %369 : int[] = prim::ListConstruct(%345, %346), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0
  %370 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.1, %369), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.0 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %371 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %372 : Tensor?[] = prim::ListConstruct(%top_x.1, %idx.1), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %373 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%371, %372), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.1 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%370, %373), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.3 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.1, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.3 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.1, %44, %top_x.1, %current_hidden_states.3, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %377 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %378 : Tensor[] = aten::where(%377), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.3 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.3 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%378), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %381 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %382 : Tensor?[] = prim::ListConstruct(%40, %top_x.3), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %383 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%381, %382), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %384 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.11 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%383, %384), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.3 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="w2"](%_1)
  %w3.3 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="w3"](%_1)
  %w1.3 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="w1"](%_1)
  %389 : int = aten::size(%hidden_states.11, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %390 : int = aten::size(%hidden_states.11, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %391 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1
  %input.15 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.11, %391), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.129 : Tensor = prim::GetAttr[name="weight"](%w1.3)
  %394 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %395 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %396 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %397 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1
  %input.17 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.15, %weight.129, %40, %394, %395, %396, %36, %397, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %399 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.131 : Tensor = prim::GetAttr[name="weight"](%w3.3)
  %401 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %402 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %403 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %404 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3
  %405 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.15, %weight.131, %40, %401, %402, %403, %36, %404, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.19 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%399, %405), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.133 : Tensor = prim::GetAttr[name="weight"](%w2.3)
  %408 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %409 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %410 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %411 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2
  %out.3 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.19, %weight.133, %40, %408, %409, %410, %36, %411, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1/__module.model.model.layers.0.block_sparse_moe.experts.1.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %413 : int[] = prim::ListConstruct(%389, %390), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1
  %414 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.3, %413), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.1 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %415 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %416 : Tensor?[] = prim::ListConstruct(%top_x.3, %idx.3), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %417 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%415, %416), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.5 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%414, %417), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.7 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.5, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.5 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.3, %44, %top_x.3, %current_hidden_states.7, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %421 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %422 : Tensor[] = aten::where(%421), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.5 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.5 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%422), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %425 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %426 : Tensor?[] = prim::ListConstruct(%40, %top_x.5), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %427 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%425, %426), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %428 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.13 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%427, %428), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.5 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="w2"](%_2)
  %w3.5 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="w3"](%_2)
  %w1.5 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="w1"](%_2)
  %433 : int = aten::size(%hidden_states.13, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %434 : int = aten::size(%hidden_states.13, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %435 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2
  %input.21 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.13, %435), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.135 : Tensor = prim::GetAttr[name="weight"](%w1.5)
  %438 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %439 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %440 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %441 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1
  %input.23 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.21, %weight.135, %40, %438, %439, %440, %36, %441, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %443 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.23), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.137 : Tensor = prim::GetAttr[name="weight"](%w3.5)
  %445 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %446 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %447 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %448 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3
  %449 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.21, %weight.137, %40, %445, %446, %447, %36, %448, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.25 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%443, %449), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.139 : Tensor = prim::GetAttr[name="weight"](%w2.5)
  %452 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %453 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %454 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %455 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2
  %out.5 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.25, %weight.139, %40, %452, %453, %454, %36, %455, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2/__module.model.model.layers.0.block_sparse_moe.experts.2.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %457 : int[] = prim::ListConstruct(%433, %434), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2
  %458 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.5, %457), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.2 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %459 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %460 : Tensor?[] = prim::ListConstruct(%top_x.5, %idx.5), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %461 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%459, %460), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.9 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%458, %461), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.11 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.9, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.7 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.5, %44, %top_x.5, %current_hidden_states.11, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %465 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %30), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %466 : Tensor[] = aten::where(%465), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.7 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.7 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%466), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %469 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %470 : Tensor?[] = prim::ListConstruct(%40, %top_x.7), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %471 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%469, %470), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %472 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.15 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%471, %472), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.7 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="w2"](%_3)
  %w3.7 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="w3"](%_3)
  %w1.7 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="w1"](%_3)
  %477 : int = aten::size(%hidden_states.15, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %478 : int = aten::size(%hidden_states.15, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %479 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3
  %input.27 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.15, %479), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.141 : Tensor = prim::GetAttr[name="weight"](%w1.7)
  %482 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %483 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %484 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %485 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1
  %input.29 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.27, %weight.141, %40, %482, %483, %484, %36, %485, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %487 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.143 : Tensor = prim::GetAttr[name="weight"](%w3.7)
  %489 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %490 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %491 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %492 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3
  %493 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.27, %weight.143, %40, %489, %490, %491, %36, %492, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.31 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%487, %493), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.145 : Tensor = prim::GetAttr[name="weight"](%w2.7)
  %496 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %497 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %498 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %499 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2
  %out.7 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.31, %weight.145, %40, %496, %497, %498, %36, %499, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3/__module.model.model.layers.0.block_sparse_moe.experts.3.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %501 : int[] = prim::ListConstruct(%477, %478), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3
  %502 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.7, %501), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.3 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %503 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %504 : Tensor?[] = prim::ListConstruct(%top_x.7, %idx.7), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %505 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%503, %504), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.13 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%502, %505), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.15 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.13, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.9 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.7, %44, %top_x.7, %current_hidden_states.15, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %509 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %25), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %510 : Tensor[] = aten::where(%509), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.9 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.9 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%510), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %513 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %514 : Tensor?[] = prim::ListConstruct(%40, %top_x.9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %515 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%513, %514), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %516 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.17 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%515, %516), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.9 : __torch__.torch.nn.modules.conv.___torch_mangle_19.Conv2d = prim::GetAttr[name="w2"](%_4)
  %w3.9 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="w3"](%_4)
  %w1.9 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="w1"](%_4)
  %521 : int = aten::size(%hidden_states.17, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %522 : int = aten::size(%hidden_states.17, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %523 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4
  %input.33 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.17, %523), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.147 : Tensor = prim::GetAttr[name="weight"](%w1.9)
  %526 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %527 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %528 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %529 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1
  %input.35 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.33, %weight.147, %40, %526, %527, %528, %36, %529, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %531 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.149 : Tensor = prim::GetAttr[name="weight"](%w3.9)
  %533 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %534 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %535 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %536 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3
  %537 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.33, %weight.149, %40, %533, %534, %535, %36, %536, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.37 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%531, %537), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.151 : Tensor = prim::GetAttr[name="weight"](%w2.9)
  %540 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %541 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %542 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %543 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2
  %out.9 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.37, %weight.151, %40, %540, %541, %542, %36, %543, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4/__module.model.model.layers.0.block_sparse_moe.experts.4.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %545 : int[] = prim::ListConstruct(%521, %522), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4
  %546 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.9, %545), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.4 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %547 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %548 : Tensor?[] = prim::ListConstruct(%top_x.9, %idx.9), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %549 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%547, %548), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.17 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%546, %549), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.19 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.17, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.11 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.9, %44, %top_x.9, %current_hidden_states.19, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %553 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %37), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %554 : Tensor[] = aten::where(%553), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.11 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.11 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%554), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %557 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %558 : Tensor?[] = prim::ListConstruct(%40, %top_x.11), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %559 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%557, %558), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %560 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.19 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%559, %560), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.11 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="w2"](%_5)
  %w3.11 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="w3"](%_5)
  %w1.11 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="w1"](%_5)
  %565 : int = aten::size(%hidden_states.19, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %566 : int = aten::size(%hidden_states.19, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %567 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5
  %input.39 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.19, %567), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.153 : Tensor = prim::GetAttr[name="weight"](%w1.11)
  %570 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %571 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %572 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %573 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1
  %input.41 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.39, %weight.153, %40, %570, %571, %572, %36, %573, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %575 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.155 : Tensor = prim::GetAttr[name="weight"](%w3.11)
  %577 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %578 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %579 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %580 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3
  %581 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.39, %weight.155, %40, %577, %578, %579, %36, %580, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.43 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%575, %581), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.157 : Tensor = prim::GetAttr[name="weight"](%w2.11)
  %584 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %585 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %586 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %587 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2
  %out.11 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.43, %weight.157, %40, %584, %585, %586, %36, %587, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5/__module.model.model.layers.0.block_sparse_moe.experts.5.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %589 : int[] = prim::ListConstruct(%565, %566), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5
  %590 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.11, %589), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.5 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %591 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %592 : Tensor?[] = prim::ListConstruct(%top_x.11, %idx.11), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %593 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%591, %592), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.21 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%590, %593), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.23 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.21, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.13 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.11, %44, %top_x.11, %current_hidden_states.23, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %597 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %12), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %598 : Tensor[] = aten::where(%597), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.13 : Long(64, strides=[1], requires_grad=0, device=cpu), %top_x.13 : Long(64, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%598), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %601 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %602 : Tensor?[] = prim::ListConstruct(%40, %top_x.13), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %603 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::index(%601, %602), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %604 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.21 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%603, %604), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.13 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="w2"](%_6)
  %w3.13 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="w3"](%_6)
  %w1.13 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="w1"](%_6)
  %609 : int = aten::size(%hidden_states.21, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %610 : int = aten::size(%hidden_states.21, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %611 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6
  %input.45 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.21, %611), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.159 : Tensor = prim::GetAttr[name="weight"](%w1.13)
  %614 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %615 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %616 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %617 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1
  %input.47 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.45, %weight.159, %40, %614, %615, %616, %36, %617, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %619 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.47), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.161 : Tensor = prim::GetAttr[name="weight"](%w3.13)
  %621 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %622 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %623 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %624 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3
  %625 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.45, %weight.161, %40, %621, %622, %623, %36, %624, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.49 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%619, %625), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.163 : Tensor = prim::GetAttr[name="weight"](%w2.13)
  %628 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %629 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %630 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %631 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2
  %out.13 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.49, %weight.163, %40, %628, %629, %630, %36, %631, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6/__module.model.model.layers.0.block_sparse_moe.experts.6.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %633 : int[] = prim::ListConstruct(%609, %610), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6
  %634 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.13, %633), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.6 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %635 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %636 : Tensor?[] = prim::ListConstruct(%top_x.13, %idx.13), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %637 : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%635, %636), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.25 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%634, %637), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.27 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.25, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.15 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.13, %44, %top_x.13, %current_hidden_states.27, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %641 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %13), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %642 : Tensor[] = aten::where(%641), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.15 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.15 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%642), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %645 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %646 : Tensor?[] = prim::ListConstruct(%40, %top_x.15), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %647 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%645, %646), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %648 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.23 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%647, %648), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.15 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="w2"](%_7)
  %w3.15 : __torch__.torch.nn.modules.conv.___torch_mangle_32.Conv2d = prim::GetAttr[name="w3"](%_7)
  %w1.15 : __torch__.torch.nn.modules.conv.___torch_mangle_30.Conv2d = prim::GetAttr[name="w1"](%_7)
  %653 : int = aten::size(%hidden_states.23, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %654 : int = aten::size(%hidden_states.23, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %655 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7
  %input.51 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.23, %655), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.165 : Tensor = prim::GetAttr[name="weight"](%w1.15)
  %658 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %659 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %660 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %661 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1
  %input.53 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.51, %weight.165, %40, %658, %659, %660, %36, %661, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %663 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.53), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.167 : Tensor = prim::GetAttr[name="weight"](%w3.15)
  %665 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %666 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %667 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %668 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3
  %669 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.51, %weight.167, %40, %665, %666, %667, %36, %668, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.55 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%663, %669), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.169 : Tensor = prim::GetAttr[name="weight"](%w2.15)
  %672 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %673 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %674 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %675 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2
  %out.15 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.55, %weight.169, %40, %672, %673, %674, %36, %675, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7/__module.model.model.layers.0.block_sparse_moe.experts.7.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %677 : int[] = prim::ListConstruct(%653, %654), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7
  %678 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.15, %677), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.7 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %679 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %680 : Tensor?[] = prim::ListConstruct(%top_x.15, %idx.15), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %681 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%679, %680), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.29 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%678, %681), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.31 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.29, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.17 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.15, %44, %top_x.15, %current_hidden_states.31, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %685 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %686 : Tensor[] = aten::where(%685), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.17 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.17 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%686), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %689 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %690 : Tensor?[] = prim::ListConstruct(%40, %top_x.17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %691 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%689, %690), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %692 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.25 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%691, %692), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.17 : __torch__.torch.nn.modules.conv.___torch_mangle_35.Conv2d = prim::GetAttr[name="w2"](%_8)
  %w3.17 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="w3"](%_8)
  %w1.17 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="w1"](%_8)
  %697 : int = aten::size(%hidden_states.25, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %698 : int = aten::size(%hidden_states.25, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %699 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8
  %input.57 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.25, %699), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.171 : Tensor = prim::GetAttr[name="weight"](%w1.17)
  %702 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %703 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %704 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %705 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1
  %input.59 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.57, %weight.171, %40, %702, %703, %704, %36, %705, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %707 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.59), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.173 : Tensor = prim::GetAttr[name="weight"](%w3.17)
  %709 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %710 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %711 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %712 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3
  %713 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.57, %weight.173, %40, %709, %710, %711, %36, %712, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.61 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%707, %713), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.175 : Tensor = prim::GetAttr[name="weight"](%w2.17)
  %716 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %717 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %718 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %719 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2
  %out.17 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.61, %weight.175, %40, %716, %717, %718, %36, %719, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8/__module.model.model.layers.0.block_sparse_moe.experts.8.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %721 : int[] = prim::ListConstruct(%697, %698), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8
  %722 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.17, %721), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.8 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %723 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %724 : Tensor?[] = prim::ListConstruct(%top_x.17, %idx.17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %725 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%723, %724), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.33 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%722, %725), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.35 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.33, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.19 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.17, %44, %top_x.17, %current_hidden_states.35, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %729 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %14), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %730 : Tensor[] = aten::where(%729), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.19 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.19 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%730), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %733 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %734 : Tensor?[] = prim::ListConstruct(%40, %top_x.19), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %735 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%733, %734), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %736 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.27 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%735, %736), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.19 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="w2"](%_9)
  %w3.19 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="w3"](%_9)
  %w1.19 : __torch__.torch.nn.modules.conv.___torch_mangle_38.Conv2d = prim::GetAttr[name="w1"](%_9)
  %741 : int = aten::size(%hidden_states.27, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %742 : int = aten::size(%hidden_states.27, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %743 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9
  %input.63 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.27, %743), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.177 : Tensor = prim::GetAttr[name="weight"](%w1.19)
  %746 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %747 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %748 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %749 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1
  %input.65 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.63, %weight.177, %40, %746, %747, %748, %36, %749, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %751 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.65), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.179 : Tensor = prim::GetAttr[name="weight"](%w3.19)
  %753 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %754 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %755 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %756 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3
  %757 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.63, %weight.179, %40, %753, %754, %755, %36, %756, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.67 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%751, %757), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.181 : Tensor = prim::GetAttr[name="weight"](%w2.19)
  %760 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %761 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %762 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %763 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2
  %out.19 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.67, %weight.181, %40, %760, %761, %762, %36, %763, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9/__module.model.model.layers.0.block_sparse_moe.experts.9.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %765 : int[] = prim::ListConstruct(%741, %742), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9
  %766 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.19, %765), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.9 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %767 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %768 : Tensor?[] = prim::ListConstruct(%top_x.19, %idx.19), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %769 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%767, %768), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.37 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%766, %769), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.39 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.37, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.21 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.19, %44, %top_x.19, %current_hidden_states.39, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %773 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %15), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %774 : Tensor[] = aten::where(%773), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.21 : Long(64, strides=[1], requires_grad=0, device=cpu), %top_x.21 : Long(64, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%774), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %777 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %778 : Tensor?[] = prim::ListConstruct(%40, %top_x.21), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %779 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::index(%777, %778), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %780 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.29 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%779, %780), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.21 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="w2"](%_10)
  %w3.21 : __torch__.torch.nn.modules.conv.___torch_mangle_44.Conv2d = prim::GetAttr[name="w3"](%_10)
  %w1.21 : __torch__.torch.nn.modules.conv.___torch_mangle_42.Conv2d = prim::GetAttr[name="w1"](%_10)
  %785 : int = aten::size(%hidden_states.29, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %786 : int = aten::size(%hidden_states.29, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %787 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10
  %input.69 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.29, %787), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.183 : Tensor = prim::GetAttr[name="weight"](%w1.21)
  %790 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %791 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %792 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %793 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1
  %input.71 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.69, %weight.183, %40, %790, %791, %792, %36, %793, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %795 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.71), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.185 : Tensor = prim::GetAttr[name="weight"](%w3.21)
  %797 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %798 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %799 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %800 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3
  %801 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.69, %weight.185, %40, %797, %798, %799, %36, %800, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.73 : Half(64, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%795, %801), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.187 : Tensor = prim::GetAttr[name="weight"](%w2.21)
  %804 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %805 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %806 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %807 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2
  %out.21 : Half(64, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.73, %weight.187, %40, %804, %805, %806, %36, %807, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10/__module.model.model.layers.0.block_sparse_moe.experts.10.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %809 : int[] = prim::ListConstruct(%785, %786), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10
  %810 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.21, %809), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.10 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %811 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %812 : Tensor?[] = prim::ListConstruct(%top_x.21, %idx.21), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %813 : Half(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%811, %812), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.41 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%810, %813), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.43 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.41, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.23 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.21, %44, %top_x.21, %current_hidden_states.43, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %817 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %16), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %818 : Tensor[] = aten::where(%817), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.23 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.23 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%818), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %821 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %822 : Tensor?[] = prim::ListConstruct(%40, %top_x.23), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %823 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%821, %822), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %824 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.31 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%823, %824), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.23 : __torch__.torch.nn.modules.conv.___torch_mangle_47.Conv2d = prim::GetAttr[name="w2"](%_11)
  %w3.23 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="w3"](%_11)
  %w1.23 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="w1"](%_11)
  %829 : int = aten::size(%hidden_states.31, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %830 : int = aten::size(%hidden_states.31, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %831 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11
  %input.75 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.31, %831), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.189 : Tensor = prim::GetAttr[name="weight"](%w1.23)
  %834 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %835 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %836 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %837 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1
  %input.77 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.75, %weight.189, %40, %834, %835, %836, %36, %837, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %839 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.77), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.191 : Tensor = prim::GetAttr[name="weight"](%w3.23)
  %841 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %842 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %843 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %844 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3
  %845 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.75, %weight.191, %40, %841, %842, %843, %36, %844, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.79 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%839, %845), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.193 : Tensor = prim::GetAttr[name="weight"](%w2.23)
  %848 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %849 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %850 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %851 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2
  %out.23 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.79, %weight.193, %40, %848, %849, %850, %36, %851, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11/__module.model.model.layers.0.block_sparse_moe.experts.11.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %853 : int[] = prim::ListConstruct(%829, %830), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11
  %854 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.23, %853), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.11 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %855 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %856 : Tensor?[] = prim::ListConstruct(%top_x.23, %idx.23), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %857 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%855, %856), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.45 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%854, %857), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.47 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.45, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.25 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.23, %44, %top_x.23, %current_hidden_states.47, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %861 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %17), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %862 : Tensor[] = aten::where(%861), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.25 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.25 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%862), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %865 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %866 : Tensor?[] = prim::ListConstruct(%40, %top_x.25), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %867 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%865, %866), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %868 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.33 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%867, %868), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.25 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="w2"](%_12)
  %w3.25 : __torch__.torch.nn.modules.conv.___torch_mangle_52.Conv2d = prim::GetAttr[name="w3"](%_12)
  %w1.25 : __torch__.torch.nn.modules.conv.___torch_mangle_50.Conv2d = prim::GetAttr[name="w1"](%_12)
  %873 : int = aten::size(%hidden_states.33, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %874 : int = aten::size(%hidden_states.33, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %875 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12
  %input.81 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.33, %875), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.195 : Tensor = prim::GetAttr[name="weight"](%w1.25)
  %878 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %879 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %880 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %881 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1
  %input.83 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.81, %weight.195, %40, %878, %879, %880, %36, %881, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %883 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.83), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.197 : Tensor = prim::GetAttr[name="weight"](%w3.25)
  %885 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %886 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %887 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %888 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3
  %889 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.81, %weight.197, %40, %885, %886, %887, %36, %888, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.85 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%883, %889), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.199 : Tensor = prim::GetAttr[name="weight"](%w2.25)
  %892 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %893 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %894 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %895 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2
  %out.25 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.85, %weight.199, %40, %892, %893, %894, %36, %895, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12/__module.model.model.layers.0.block_sparse_moe.experts.12.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %897 : int[] = prim::ListConstruct(%873, %874), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12
  %898 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.25, %897), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.12 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %899 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %900 : Tensor?[] = prim::ListConstruct(%top_x.25, %idx.25), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %901 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%899, %900), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.49 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%898, %901), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.51 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.49, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.27 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.25, %44, %top_x.25, %current_hidden_states.51, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %905 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %18), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %906 : Tensor[] = aten::where(%905), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.27 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.27 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%906), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %909 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %910 : Tensor?[] = prim::ListConstruct(%40, %top_x.27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %911 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%909, %910), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %912 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.35 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%911, %912), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.27 : __torch__.torch.nn.modules.conv.___torch_mangle_55.Conv2d = prim::GetAttr[name="w2"](%_13)
  %w3.27 : __torch__.torch.nn.modules.conv.___torch_mangle_56.Conv2d = prim::GetAttr[name="w3"](%_13)
  %w1.27 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="w1"](%_13)
  %917 : int = aten::size(%hidden_states.35, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %918 : int = aten::size(%hidden_states.35, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %919 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13
  %input.87 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.35, %919), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.201 : Tensor = prim::GetAttr[name="weight"](%w1.27)
  %922 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %923 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %924 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %925 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1
  %input.89 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.87, %weight.201, %40, %922, %923, %924, %36, %925, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %927 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.89), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.203 : Tensor = prim::GetAttr[name="weight"](%w3.27)
  %929 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %930 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %931 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %932 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3
  %933 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.87, %weight.203, %40, %929, %930, %931, %36, %932, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.91 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%927, %933), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.205 : Tensor = prim::GetAttr[name="weight"](%w2.27)
  %936 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %937 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %938 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %939 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2
  %out.27 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.91, %weight.205, %40, %936, %937, %938, %36, %939, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13/__module.model.model.layers.0.block_sparse_moe.experts.13.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %941 : int[] = prim::ListConstruct(%917, %918), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13
  %942 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.27, %941), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.13 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %943 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %944 : Tensor?[] = prim::ListConstruct(%top_x.27, %idx.27), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %945 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%943, %944), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.53 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%942, %945), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.55 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.53, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.29 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.27, %44, %top_x.27, %current_hidden_states.55, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %949 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %19), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %950 : Tensor[] = aten::where(%949), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx.29 : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x.29 : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%950), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %953 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %954 : Tensor?[] = prim::ListConstruct(%40, %top_x.29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %955 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%953, %954), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %956 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states.37 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%955, %956), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2.29 : __torch__.torch.nn.modules.conv.___torch_mangle_59.Conv2d = prim::GetAttr[name="w2"](%_14)
  %w3.29 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="w3"](%_14)
  %w1.29 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="w1"](%_14)
  %961 : int = aten::size(%hidden_states.37, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %962 : int = aten::size(%hidden_states.37, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %963 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14
  %input.93 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states.37, %963), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.207 : Tensor = prim::GetAttr[name="weight"](%w1.29)
  %966 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %967 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %968 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %969 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1
  %input.95 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.93, %weight.207, %40, %966, %967, %968, %36, %969, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %971 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.95), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.209 : Tensor = prim::GetAttr[name="weight"](%w3.29)
  %973 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %974 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %975 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %976 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3
  %977 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.93, %weight.209, %40, %973, %974, %975, %36, %976, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input.97 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%971, %977), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight.211 : Tensor = prim::GetAttr[name="weight"](%w2.29)
  %980 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %981 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %982 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %983 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2
  %out.29 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.97, %weight.211, %40, %980, %981, %982, %36, %983, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14/__module.model.model.layers.0.block_sparse_moe.experts.14.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %985 : int[] = prim::ListConstruct(%961, %962), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14
  %986 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out.29, %985), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.14 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %987 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %988 : Tensor?[] = prim::ListConstruct(%top_x.29, %idx.29), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %989 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%987, %988), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.57 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%986, %989), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.59 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.57, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states.31 : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.29, %44, %top_x.29, %current_hidden_states.59, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %993 : Long(2, 64, strides=[16, 32], requires_grad=0, device=cpu) = aten::select(%expert_mask, %44, %20), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %994 : Tensor[] = aten::where(%993), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:630:0
  %idx : Long(0, strides=[1], requires_grad=0, device=cpu), %top_x : Long(0, strides=[1], requires_grad=0, device=cpu) = prim::ListUnpack(%994), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %997 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%hidden_states.7, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %998 : Tensor?[] = prim::ListConstruct(%40, %top_x), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %999 : Half(1, 0, 4096, strides=[4096, 4096, 1], requires_grad=1, device=cpu) = aten::index(%997, %998), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %1000 : int[] = prim::ListConstruct(%27, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %hidden_states : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::reshape(%999, %1000), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:651:0
  %w2 : __torch__.torch.nn.modules.conv.___torch_mangle_63.Conv2d = prim::GetAttr[name="w2"](%_15)
  %w3 : __torch__.torch.nn.modules.conv.___torch_mangle_64.Conv2d = prim::GetAttr[name="w3"](%_15)
  %w1 : __torch__.torch.nn.modules.conv.___torch_mangle_62.Conv2d = prim::GetAttr[name="w1"](%_15)
  %1005 : int = aten::size(%hidden_states, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %1006 : int = aten::size(%hidden_states, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:545:0
  %1007 : int[] = prim::ListConstruct(%27, %33, %41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15
  %input.99 : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=1, device=cpu) = aten::view(%hidden_states, %1007), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:547:0
  %weight.213 : Tensor = prim::GetAttr[name="weight"](%w1)
  %1010 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %1011 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %1012 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %1013 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1
  %input.101 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.99, %weight.213, %40, %1010, %1011, %1012, %36, %1013, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w1 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %1015 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::silu(%input.101), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/functional.py:2380:0
  %weight.215 : Tensor = prim::GetAttr[name="weight"](%w3)
  %1017 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1018 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1019 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1020 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3
  %1021 : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.99, %weight.215, %40, %1017, %1018, %1019, %36, %1020, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w3 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %input : Half(0, 6400, 1, 1, strides=[6400, 1, 1, 1], requires_grad=1, device=cpu) = aten::mul(%1015, %1021), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:549:0
  %weight : Tensor = prim::GetAttr[name="weight"](%w2)
  %1024 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %1025 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %1026 : int[] = prim::ListConstruct(%41, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %1027 : int[] = prim::ListConstruct(%44, %44), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2
  %out : Half(0, 4096, 1, 1, strides=[4096, 1, 1, 1], requires_grad=0, device=cpu) = aten::_convolution(%input, %weight, %40, %1024, %1025, %1026, %36, %1027, %41, %36, %36, %35, %35), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15/__module.model.model.layers.0.block_sparse_moe.experts.15.w2 # /Users/felixlin/workspace-apple-silicon/myenv-python39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549:0
  %1029 : int[] = prim::ListConstruct(%1005, %1006), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15
  %1030 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::view(%out, %1029), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe/__module.model.model.layers.0.block_sparse_moe.experts.15 # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:551:0
  %1031 : Half(64, 2, 1, strides=[2, 1, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%routing_weights, %32), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %1032 : Tensor?[] = prim::ListConstruct(%top_x, %idx), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %1033 : Half(0, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::index(%1031, %1032), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states.61 : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::mul(%1030, %1033), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:652:0
  %current_hidden_states : Half(0, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::to(%current_hidden_states.61, %37, %36, %36, %40), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %final_hidden_states : Half(64, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = aten::index_add_(%final_hidden_states.31, %44, %top_x, %current_hidden_states, %41), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:661:0
  %1037 : int[] = prim::ListConstruct(%280, %282, %284), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe
  %1038 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::reshape(%final_hidden_states, %1037), scope: __module.model.model/__module.model.model.layers.0.block_sparse_moe # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:664:0
  %1039 : Half(1, 64, 4096, strides=[262144, 4096, 1], requires_grad=1, device=cpu) = aten::add(%input.5, %1038, %41), scope: __module.model.model # /Users/felixlin/workspace-apple-silicon/Anemll/anemll/models/phimoe_model.py:1300:0
  return (%1039)